{"cells":[{"cell_type":"code","execution_count":1,"id":"da3b6ba1","metadata":{},"outputs":[],"source":"import os\nimport functools\nfrom typing import *\nfrom glob import glob\nimport pickle\n\nimport torch\nimport numpy as np\nimport pandas as pd\n\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data.dataloader import DataLoader\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n#from sklearn.manifold import TSNE\nfrom MulticoreTSNE import MulticoreTSNE as TSNE\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial import cKDTree\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom yellowbrick.features import Manifold\nfrom yellowbrick.cluster import KElbowVisualizer, InterclusterDistance, SilhouetteVisualizer\nfrom sklearn.preprocessing import normalize\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom sklearn.cluster import AgglomerativeClustering\nfrom altlabs.index_mapping import create_index_mapping\nfrom altlabs.dataset import (\n    noop,\n    random_roll,\n    SoftmaxDataset,\n    limit_sequence_size,\n    FactorizationDataset,\n)\nfrom altlabs.torch.data import FasterBatchSampler, NoAutoCollationDataLoader\nfrom altlabs.utils import Pipeline\nfrom pytorch_lightning import seed_everything\nfrom sklearn.metrics import top_k_accuracy_score\n%matplotlib inline"},{"cell_type":"code","execution_count":2,"id":"bd8dfe7e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:root:Not using Catalysis: No module named 'catalysis'\n"]},{"name":"stdout","output_type":"stream","text":["stripping - WARNING - Not using Catalysis: No module named 'catalysis'\n","output/b4a3cfe8-8678-4253-a9fa-62d7a5e300a8/tensorboard_logs_csv_logs/0_0/lab_index_mapping.pkl\n"]},{"name":"stderr","output_type":"stream","text":["/home/robot/ds-projects/altlabs_codeocean/code/altlabs/dataset.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  self._sequences = np.array([np.array(s) for s in self._sequences])\n"]},{"name":"stdout","output_type":"stream","text":["output/b4a3cfe8-8678-4253-a9fa-62d7a5e300a8/tensorboard_logs_csv_logs/1_1/lab_index_mapping.pkl\n","output/b4a3cfe8-8678-4253-a9fa-62d7a5e300a8/tensorboard_logs_csv_logs/2_2/lab_index_mapping.pkl\n","output/b4a3cfe8-8678-4253-a9fa-62d7a5e300a8/tensorboard_logs_csv_logs/3_3/lab_index_mapping.pkl\n","output/94ccb688-76df-437e-8efc-61ed33bc746f/tensorboard_logs_csv_logs/0_0/lab_index_mapping.pkl\n"]},{"name":"stderr","output_type":"stream","text":["/home/robot/ds-projects/altlabs_codeocean/code/altlabs/dataset.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  self._sequences = np.array([np.array(s) for s in self._sequences])\n"]},{"name":"stdout","output_type":"stream","text":["output/94ccb688-76df-437e-8efc-61ed33bc746f/tensorboard_logs_csv_logs/1_1/lab_index_mapping.pkl\n","output/94ccb688-76df-437e-8efc-61ed33bc746f/tensorboard_logs_csv_logs/2_2/lab_index_mapping.pkl\n","output/94ccb688-76df-437e-8efc-61ed33bc746f/tensorboard_logs_csv_logs/3_3/lab_index_mapping.pkl\n","output/c371dd6a-5da5-47e3-82d3-a1e351d5b045/tensorboard_logs_csv_logs/0_0/lab_index_mapping.pkl\n"]},{"name":"stderr","output_type":"stream","text":["/home/robot/ds-projects/altlabs_codeocean/code/altlabs/dataset.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  self._sequences = np.array([np.array(s) for s in self._sequences])\n"]},{"name":"stdout","output_type":"stream","text":["output/c371dd6a-5da5-47e3-82d3-a1e351d5b045/tensorboard_logs_csv_logs/1_1/lab_index_mapping.pkl\n","output/c371dd6a-5da5-47e3-82d3-a1e351d5b045/tensorboard_logs_csv_logs/2_2/lab_index_mapping.pkl\n","output/c371dd6a-5da5-47e3-82d3-a1e351d5b045/tensorboard_logs_csv_logs/3_3/lab_index_mapping.pkl\n","output/3d70caa8-06d2-4247-a663-53c3be194a0d/tensorboard_logs_csv_logs/0_0/lab_index_mapping.pkl\n"]},{"name":"stderr","output_type":"stream","text":["/home/robot/ds-projects/altlabs_codeocean/code/altlabs/dataset.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  self._sequences = np.array([np.array(s) for s in self._sequences])\n"]},{"name":"stdout","output_type":"stream","text":["output/3d70caa8-06d2-4247-a663-53c3be194a0d/tensorboard_logs_csv_logs/1_1/lab_index_mapping.pkl\n","output/3d70caa8-06d2-4247-a663-53c3be194a0d/tensorboard_logs_csv_logs/2_2/lab_index_mapping.pkl\n"]}],"source":"triplet_model_seq_limit_4000_paths = list(sorted(glob(\"output/b4a3cfe8-8678-4253-a9fa-62d7a5e300a8/tensorboard_logs_csv_logs/*/checkpoints/*.ckpt\")))\nlab_index_mapping_seq_limit_4000_paths = list(sorted(glob(\"output/b4a3cfe8-8678-4253-a9fa-62d7a5e300a8/tensorboard_logs_csv_logs/*/lab_index_mapping.pkl\")))\nfrom altlabs.model.conv1d_triplet_classifier import Conv1dTripletClassifier, ModelConfig"},{"cell_type":"code","execution_count":3,"id":"41251582","metadata":{},"outputs":[{"data":{"text/plain":["['output/b4a3cfe8-8678-4253-a9fa-62d7a5e300a8/tensorboard_logs_csv_logs/0_0/lab_index_mapping.pkl',\n"," 'output/b4a3cfe8-8678-4253-a9fa-62d7a5e300a8/tensorboard_logs_csv_logs/1_1/lab_index_mapping.pkl',\n"," 'output/b4a3cfe8-8678-4253-a9fa-62d7a5e300a8/tensorboard_logs_csv_logs/2_2/lab_index_mapping.pkl',\n"," 'output/b4a3cfe8-8678-4253-a9fa-62d7a5e300a8/tensorboard_logs_csv_logs/3_3/lab_index_mapping.pkl']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":"lab_index_mapping_seq_limit_4000_paths"},{"cell_type":"code","execution_count":4,"id":"ca712b89","metadata":{},"outputs":[],"source":"DATA_PATH = \"../data/\""},{"cell_type":"code","execution_count":5,"id":"118a5bfb","metadata":{},"outputs":[],"source":"device = torch.device(\"cuda:0\")\n\ntrain_values_df = pd.read_csv(f\"{DATA_PATH}train_values_grouped.csv\")\nformat_df = pd.read_csv(f\"{DATA_PATH}format.csv\")\ntest_values_df = pd.read_csv(f\"{DATA_PATH}test_values.csv\")\ntest_set = pd.read_csv(f\"{DATA_PATH}test_labels.csv\")\npub_id = pd.read_csv(f\"{DATA_PATH}pubsubidx.csv\")"},{"cell_type":"code","execution_count":6,"id":"2df3e272","metadata":{},"outputs":[],"source":"pub_index = pub_id[pub_id.public==True].index\nprivate_index = pub_id[pub_id.public==False].index"},{"cell_type":"code","execution_count":7,"id":"fbadc9a9","metadata":{},"outputs":[],"source":"seed_everything(350)\ndef predict_dataset(model: Conv1dTripletClassifier, dataset: FactorizationDataset, tta_steps: int) -> np.ndarray:\n    batch_sampler = FasterBatchSampler(\n        dataset, 32, shuffle=False,\n    )\n\n    model.to(device)\n\n    predictions: List[List[float]] = []\n    with torch.no_grad():\n        for indices in batch_sampler:\n            if tta_steps > 0:\n                tta_predictions = []\n                for i in range(tta_steps):\n                    batch = dataset[indices]\n                    if isinstance(batch[0], tuple):\n                        (sequences, extra_inputs, _) = batch[\n                            0\n                        ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n                    else:\n                        (sequences, extra_inputs) = batch\n                    outputs = model.predict_lab_scores(\n                        sequences.to(device), extra_inputs.to(device)\n                    ).tolist()\n                    tta_predictions.append(np.array(outputs))\n                predictions.extend(\n                    np.mean(np.array(tta_predictions), axis=0).tolist()\n                )\n            else:\n                batch = dataset[indices]\n                if isinstance(batch[0], tuple):\n                    (sequences, extra_inputs, _) = batch[\n                        0\n                    ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n                else:\n                    (sequences, extra_inputs) = batch\n                outputs = model.predict_lab_scores(\n                    sequences.to(device), extra_inputs.to(device)\n                ).tolist()\n                predictions.extend(outputs)\n\n    return np.array(predictions)\n\nsequence_index_mapping = create_index_mapping(\n\"ATGC\", include_unkown=True, include_none=False,\n)\nsequence_index_mapping[\"N\"] = 0\ninput_columns = train_values_df.drop(columns=[\"sequence_id\", \"groups\", \"output\"]).columns\n\nfold_output = []\nfor triplet_model_path, lab_index_mapping_path in zip(triplet_model_seq_limit_4000_paths, lab_index_mapping_seq_limit_4000_paths):\n    print(lab_index_mapping_path)\n    model = Conv1dTripletClassifier.load_from_checkpoint(triplet_model_path)\n    with open(lab_index_mapping_path, \"rb\") as f:\n        lab_index_mapping = pickle.load(f)\n    dataset = FactorizationDataset(\n        test_values_df,\n        sequence_index_mapping,\n        lab_index_mapping,\n        input_columns,\n        lab_column=\"output\",\n        negative_proportion=0.0,\n        transform_sequence_fn=random_roll,\n        test=True,\n        bpe=True,\n    )\n\n    outputs = predict_dataset(model, dataset, 10)\n    fold_output.append(outputs)\nfinal_outputs = np.mean(fold_output, axis=0)\n\nfor lab in format_df.columns[1:]:\n    lab_index = lab_index_mapping[lab]\n    format_df[lab] = final_outputs[:, lab_index]\n\nformat_df = format_df.round(6)\n\n\n    "},{"cell_type":"code","execution_count":8,"id":"5f79b672","metadata":{},"outputs":[{"data":{"text/plain":["'Triplet model top-10 private score: 0.8670601709100519'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-1 private score: 0.6856664611047485'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-10 public score: 0.8821165438713998'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-1 public score: 0.7402545210984595'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-10 total score: 0.8730335884353742'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-1 total score: 0.7073235544217688'"]},"metadata":{},"output_type":"display_data"}],"source":"pub_best_sub = format_df[format_df.index.isin(pub_index)]\nprivate_best_sub = format_df[format_df.index.isin(private_index)]\nprivate_test = test_set[test_set.index.isin(private_index)]\npublic_test = test_set[test_set.index.isin(pub_index)]\nprivate_labels = private_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\npublic_labels = public_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n\ntop_10_score_private_4000 = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_private_4000 = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ntop_10_score_public_4000 = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_public_4000 = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ntop_10_score_total_4000 = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), format_df.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_total_4000 = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), format_df.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ndisplay(f\"Triplet model top-10 private score: {top_10_score_private_4000}\")\n\ndisplay(f\"Triplet model top-1 private score: {top_1_score_private_4000}\")\n\n\ndisplay(f\"Triplet model top-10 public score: {top_10_score_public_4000}\")\n\ndisplay(f\"Triplet model top-1 public score: {top_1_score_public_4000}\")\n\ndisplay(f\"Triplet model top-10 total score: {top_10_score_total_4000}\")\n\ndisplay(f\"Triplet model top-1 total score: {top_1_score_total_4000}\")"},{"cell_type":"code","execution_count":9,"id":"be833395","metadata":{},"outputs":[],"source":"triplet_model_seq_limit_3000_paths = list(sorted(glob(\"output/94ccb688-76df-437e-8efc-61ed33bc746f/tensorboard_logs_csv_logs/*/checkpoints/*.ckpt\")))\nlab_index_mapping_seq_limit_3000_paths = list(sorted(glob(\"output/94ccb688-76df-437e-8efc-61ed33bc746f/tensorboard_logs_csv_logs/*/lab_index_mapping.pkl\")))\n"},{"cell_type":"code","execution_count":10,"id":"a884e263","metadata":{},"outputs":[],"source":"seed_everything(350)\ndef predict_dataset(model: Conv1dTripletClassifier, dataset: FactorizationDataset, tta_steps: int) -> np.ndarray:\n    batch_sampler = FasterBatchSampler(\n        dataset, 32, shuffle=False,\n    )\n\n    model.to(device)\n\n    predictions: List[List[float]] = []\n    with torch.no_grad():\n        for indices in batch_sampler:\n            if tta_steps > 0:\n                tta_predictions = []\n                for i in range(tta_steps):\n                    batch = dataset[indices]\n                    if isinstance(batch[0], tuple):\n                        (sequences, extra_inputs, _) = batch[\n                            0\n                        ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n                    else:\n                        (sequences, extra_inputs) = batch\n                    outputs = model.predict_lab_scores(\n                        sequences.to(device), extra_inputs.to(device)\n                    ).tolist()\n                    tta_predictions.append(np.array(outputs))\n                predictions.extend(\n                    np.mean(np.array(tta_predictions), axis=0).tolist()\n                )\n            else:\n                batch = dataset[indices]\n                if isinstance(batch[0], tuple):\n                    (sequences, extra_inputs, _) = batch[\n                        0\n                    ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n                else:\n                    (sequences, extra_inputs) = batch\n                outputs = model.predict_lab_scores(\n                    sequences.to(device), extra_inputs.to(device)\n                ).tolist()\n                predictions.extend(outputs)\n\n    return np.array(predictions)\n\nsequence_index_mapping = create_index_mapping(\n\"ATGC\", include_unkown=True, include_none=False,\n)\nsequence_index_mapping[\"N\"] = 0\ninput_columns = train_values_df.drop(columns=[\"sequence_id\", \"groups\", \"output\"]).columns\n\nfold_output = []\nfor triplet_model_path, lab_index_mapping_path in zip(triplet_model_seq_limit_3000_paths, lab_index_mapping_seq_limit_3000_paths):\n    print(lab_index_mapping_path)\n    model = Conv1dTripletClassifier.load_from_checkpoint(triplet_model_path)\n    with open(lab_index_mapping_path, \"rb\") as f:\n        lab_index_mapping = pickle.load(f)\n    dataset = FactorizationDataset(\n        test_values_df,\n        sequence_index_mapping,\n        lab_index_mapping,\n        input_columns,\n        lab_column=\"output\",\n        negative_proportion=0.0,\n        transform_sequence_fn=random_roll,\n        test=True,\n        bpe=True,\n    )\n\n    outputs = predict_dataset(model, dataset, 10)\n    fold_output.append(outputs)\nfinal_outputs = np.mean(fold_output, axis=0)\n\nfor lab in format_df.columns[1:]:\n    lab_index = lab_index_mapping[lab]\n    format_df[lab] = final_outputs[:, lab_index]\n\nformat_df = format_df.round(6)\n\n\n    "},{"cell_type":"code","execution_count":11,"id":"d9c4f352","metadata":{},"outputs":[{"data":{"text/plain":["'Triplet model top-10 private score: 0.8682935424191701'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-1 private score: 0.6920095145802132'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-10 public score: 0.8755525787006028'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-1 public score: 0.7438713998660416'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-10 total score: 0.8711734693877551'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-1 total score: 0.7125850340136054'"]},"metadata":{},"output_type":"display_data"}],"source":"pub_best_sub = format_df[format_df.index.isin(pub_index)]\nprivate_best_sub = format_df[format_df.index.isin(private_index)]\nprivate_test = test_set[test_set.index.isin(private_index)]\npublic_test = test_set[test_set.index.isin(pub_index)]\nprivate_labels = private_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\npublic_labels = public_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n\ntop_10_score_private_3000 = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_private_3000 = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ntop_10_score_public_3000 = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_public_3000 = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ntop_10_score_total_3000 = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), format_df.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_total_3000 = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), format_df.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ndisplay(f\"Triplet model top-10 private score: {top_10_score_private_3000}\")\n\ndisplay(f\"Triplet model top-1 private score: {top_1_score_private_3000}\")\n\n\ndisplay(f\"Triplet model top-10 public score: {top_10_score_public_3000}\")\n\ndisplay(f\"Triplet model top-1 public score: {top_1_score_public_3000}\")\n\ndisplay(f\"Triplet model top-10 total score: {top_10_score_total_3000}\")\n\ndisplay(f\"Triplet model top-1 total score: {top_1_score_total_3000}\")"},{"cell_type":"code","execution_count":12,"id":"3f0d5ef5","metadata":{},"outputs":[],"source":"triplet_model_seq_limit_2000_paths = list(sorted(glob(\"output/c371dd6a-5da5-47e3-82d3-a1e351d5b045/tensorboard_logs_csv_logs/*/checkpoints/*.ckpt\")))\nlab_index_mapping_seq_limit_2000_paths = list(sorted(glob(\"output/c371dd6a-5da5-47e3-82d3-a1e351d5b045/tensorboard_logs_csv_logs/*/lab_index_mapping.pkl\")))\n"},{"cell_type":"code","execution_count":13,"id":"aca73ca8","metadata":{},"outputs":[],"source":"seed_everything(350)\ndef predict_dataset(model: Conv1dTripletClassifier, dataset: FactorizationDataset, tta_steps: int) -> np.ndarray:\n    batch_sampler = FasterBatchSampler(\n        dataset, 32, shuffle=False,\n    )\n\n    model.to(device)\n\n    predictions: List[List[float]] = []\n    with torch.no_grad():\n        for indices in batch_sampler:\n            if tta_steps > 0:\n                tta_predictions = []\n                for i in range(tta_steps):\n                    batch = dataset[indices]\n                    if isinstance(batch[0], tuple):\n                        (sequences, extra_inputs, _) = batch[\n                            0\n                        ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n                    else:\n                        (sequences, extra_inputs) = batch\n                    outputs = model.predict_lab_scores(\n                        sequences.to(device), extra_inputs.to(device)\n                    ).tolist()\n                    tta_predictions.append(np.array(outputs))\n                predictions.extend(\n                    np.mean(np.array(tta_predictions), axis=0).tolist()\n                )\n            else:\n                batch = dataset[indices]\n                if isinstance(batch[0], tuple):\n                    (sequences, extra_inputs, _) = batch[\n                        0\n                    ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n                else:\n                    (sequences, extra_inputs) = batch\n                outputs = model.predict_lab_scores(\n                    sequences.to(device), extra_inputs.to(device)\n                ).tolist()\n                predictions.extend(outputs)\n\n    return np.array(predictions)\n\nsequence_index_mapping = create_index_mapping(\n\"ATGC\", include_unkown=True, include_none=False,\n)\nsequence_index_mapping[\"N\"] = 0\ninput_columns = train_values_df.drop(columns=[\"sequence_id\", \"groups\", \"output\"]).columns\n\nfold_output = []\nfor triplet_model_path, lab_index_mapping_path in zip(triplet_model_seq_limit_2000_paths, lab_index_mapping_seq_limit_2000_paths):\n    print(lab_index_mapping_path)\n    model = Conv1dTripletClassifier.load_from_checkpoint(triplet_model_path)\n    with open(lab_index_mapping_path, \"rb\") as f:\n        lab_index_mapping = pickle.load(f)\n    dataset = FactorizationDataset(\n        test_values_df,\n        sequence_index_mapping,\n        lab_index_mapping,\n        input_columns,\n        lab_column=\"output\",\n        negative_proportion=0.0,\n        transform_sequence_fn=random_roll,\n        test=True,\n        bpe=True,\n    )\n\n    outputs = predict_dataset(model, dataset, 10)\n    fold_output.append(outputs)\nfinal_outputs = np.mean(fold_output, axis=0)\n\nfor lab in format_df.columns[1:]:\n    lab_index = lab_index_mapping[lab]\n    format_df[lab] = final_outputs[:, lab_index]\n\nformat_df = format_df.round(6)\n\n\n    "},{"cell_type":"code","execution_count":14,"id":"4de01a17","metadata":{},"outputs":[{"data":{"text/plain":["'Triplet model top-10 private score: 0.867676856664611'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-1 private score: 0.690071359351599'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-10 public score: 0.883456128600134'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-1 public score: 0.7438713998660416'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-10 total score: 0.873937074829932'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Triplet model top-1 total score: 0.7114158163265306'"]},"metadata":{},"output_type":"display_data"}],"source":"pub_best_sub = format_df[format_df.index.isin(pub_index)]\nprivate_best_sub = format_df[format_df.index.isin(private_index)]\nprivate_test = test_set[test_set.index.isin(private_index)]\npublic_test = test_set[test_set.index.isin(pub_index)]\nprivate_labels = private_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\npublic_labels = public_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n\ntop_10_score_private_2000 = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_private_2000 = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ntop_10_score_public_2000 = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_public_2000 = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ntop_10_score_total_2000 = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), format_df.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_total_2000 = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), format_df.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ndisplay(f\"Triplet model top-10 private score: {top_10_score_private_2000}\")\n\ndisplay(f\"Triplet model top-1 private score: {top_1_score_private_2000}\")\n\n\ndisplay(f\"Triplet model top-10 public score: {top_10_score_public_2000}\")\n\ndisplay(f\"Triplet model top-1 public score: {top_1_score_public_2000}\")\n\ndisplay(f\"Triplet model top-10 total score: {top_10_score_total_2000}\")\n\ndisplay(f\"Triplet model top-1 total score: {top_1_score_total_2000}\")"},{"cell_type":"code","execution_count":15,"id":"6b6295e2","metadata":{},"outputs":[],"source":"triplet_model_seq_limit_500_paths = list(sorted(glob(\"output/3d70caa8-06d2-4247-a663-53c3be194a0d/tensorboard_logs_csv_logs/*/checkpoints/*.ckpt\")))\nlab_index_mapping_seq_limit_500_paths = list(sorted(glob(\"output/3d70caa8-06d2-4247-a663-53c3be194a0d/tensorboard_logs_csv_logs/*/lab_index_mapping.pkl\")))\n"},{"cell_type":"code","execution_count":null,"id":"a8c259ab","metadata":{},"outputs":[],"source":"seed_everything(350)\ndef predict_dataset(model: Conv1dTripletClassifier, dataset: FactorizationDataset, tta_steps: int) -> np.ndarray:\n    batch_sampler = FasterBatchSampler(\n        dataset, 32, shuffle=False,\n    )\n\n    model.to(device)\n\n    predictions: List[List[float]] = []\n    with torch.no_grad():\n        for indices in batch_sampler:\n            if tta_steps > 0:\n                tta_predictions = []\n                for i in range(tta_steps):\n                    batch = dataset[indices]\n                    if isinstance(batch[0], tuple):\n                        (sequences, extra_inputs, _) = batch[\n                            0\n                        ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n                    else:\n                        (sequences, extra_inputs) = batch\n                    outputs = model.predict_lab_scores(\n                        sequences.to(device), extra_inputs.to(device)\n                    ).tolist()\n                    tta_predictions.append(np.array(outputs))\n                predictions.extend(\n                    np.mean(np.array(tta_predictions), axis=0).tolist()\n                )\n            else:\n                batch = dataset[indices]\n                if isinstance(batch[0], tuple):\n                    (sequences, extra_inputs, _) = batch[\n                        0\n                    ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n                else:\n                    (sequences, extra_inputs) = batch\n                outputs = model.predict_lab_scores(\n                    sequences.to(device), extra_inputs.to(device)\n                ).tolist()\n                predictions.extend(outputs)\n\n    return np.array(predictions)\n\nsequence_index_mapping = create_index_mapping(\n\"ATGC\", include_unkown=True, include_none=False,\n)\nsequence_index_mapping[\"N\"] = 0\ninput_columns = train_values_df.drop(columns=[\"sequence_id\", \"groups\", \"output\"]).columns\n\nfold_output = []\nfor triplet_model_path, lab_index_mapping_path in zip(triplet_model_seq_limit_500_paths, lab_index_mapping_seq_limit_500_paths):\n    print(lab_index_mapping_path)\n    model = Conv1dTripletClassifier.load_from_checkpoint(triplet_model_path)\n    with open(lab_index_mapping_path, \"rb\") as f:\n        lab_index_mapping = pickle.load(f)\n    dataset = FactorizationDataset(\n        test_values_df,\n        sequence_index_mapping,\n        lab_index_mapping,\n        input_columns,\n        lab_column=\"output\",\n        negative_proportion=0.0,\n        transform_sequence_fn=random_roll,\n        test=True,\n        bpe=True,\n    )\n\n    outputs = predict_dataset(model, dataset, 10)\n    fold_output.append(outputs)\nfinal_outputs = np.mean(fold_output, axis=0)\n\nfor lab in format_df.columns[1:]:\n    lab_index = lab_index_mapping[lab]\n    format_df[lab] = final_outputs[:, lab_index]\n\nformat_df = format_df.round(6)\n\n\n    "},{"cell_type":"code","execution_count":null,"id":"6f9ccfff","metadata":{},"outputs":[],"source":"pub_best_sub = format_df[format_df.index.isin(pub_index)]\nprivate_best_sub = format_df[format_df.index.isin(private_index)]\nprivate_test = test_set[test_set.index.isin(private_index)]\npublic_test = test_set[test_set.index.isin(pub_index)]\nprivate_labels = private_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\npublic_labels = public_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n\ntop_10_score_private_500 = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_private_500 = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ntop_10_score_public_500 = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_public_500 = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ntop_10_score_total_500 = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), format_df.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ntop_1_score_total_500 = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), format_df.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n\ndisplay(f\"Triplet model top-10 private score: {top_10_score_private_500}\")\n\ndisplay(f\"Triplet model top-1 private score: {top_1_score_private_500}\")\n\n\ndisplay(f\"Triplet model top-10 public score: {top_10_score_public_500}\")\n\ndisplay(f\"Triplet model top-1 public score: {top_1_score_public_500}\")\n\ndisplay(f\"Triplet model top-10 total score: {top_10_score_total_500}\")\n\ndisplay(f\"Triplet model top-1 total score: {top_1_score_total_500}\")"},{"cell_type":"code","execution_count":19,"id":"b7974d4e","metadata":{},"outputs":[{"data":{"text/plain":["'Triplet model top-1 total score: 0.7242240646258503'"]},"metadata":{},"output_type":"display_data"}],"source":"display(f\"Triplet model top-1 total score: {top_1_score_total_500}\")"},{"cell_type":"code","execution_count":22,"id":"eb738223","metadata":{},"outputs":[],"source":"import os\nRESULTS_PATH = \"../results/\"\n\nif os.path.exists(f\"{RESULTS_PATH}results.csv\"):\n    result_df = pd.read_csv(f\"{RESULTS_PATH}results.csv\")\nelse:\n    result_df = pd.DataFrame([], columns=[\"Model\", \"Top 10 Score\", \"Top 1 Score\", \"Top 10 New Data Score\", \"Top 1 New Data Score\", \"Top 10 Total Score\", \"Top 1 Total Score\"])\n    \n\nresult_df = result_df.append({\"Model\": \"BPE - Seq Limit 4000\", \n                              \"Top 10 Score\": top_10_score_private_4000, \"Top 1 Score\": top_1_score_private_4000, \n                              \"Top 10 New Data Score\": top_10_score_public_4000, \"Top 1 New Data Score\": top_1_score_public_4000,\n                             \"Top 10 Total Score\": top_10_score_total_4000, \"Top 1 Total Score\": top_1_score_total_4000}, ignore_index=True)\n\nresult_df = result_df.append({\"Model\": \"BPE - Seq Limit 3000\", \n                              \"Top 10 Score\": top_10_score_private_3000, \"Top 1 Score\": top_1_score_private_3000, \n                              \"Top 10 New Data Score\": top_10_score_public_3000, \"Top 1 New Data Score\": top_1_score_public_3000,\n                             \"Top 10 Total Score\": top_10_score_total_3000, \"Top 1 Total Score\": top_1_score_total_3000}, ignore_index=True)\n\n\nresult_df = result_df.append({\"Model\": \"BPE - Seq Limit 2000\", \n                              \"Top 10 Score\": top_10_score_private_2000, \"Top 1 Score\": top_1_score_private_2000, \n                              \"Top 10 New Data Score\": top_10_score_public_2000, \"Top 1 New Data Score\": top_1_score_public_2000,\n                             \"Top 10 Total Score\": top_10_score_total_2000, \"Top 1 Total Score\": top_1_score_total_2000}, ignore_index=True)\n\n\nresult_df = result_df.append({\"Model\": \"BPE - Seq Limit 500\", \n                              \"Top 10 Score\": top_10_score_private_500, \"Top 1 Score\": top_1_score_private_500, \n                              \"Top 10 New Data Score\": top_10_score_public_500, \"Top 1 New Data Score\": top_1_score_public_500,\n                             \"Top 10 Total Score\": top_10_score_total_500, \"Top 1 Total Score\": top_1_score_total_500}, ignore_index=True)\n\n\nresult_df.to_csv(f\"{RESULTS_PATH}results.csv\", index=False)"},{"cell_type":"code","execution_count":null,"id":"e8413265","metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":5}