{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23afcad8",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning for  Pharmacology\n",
    "## Task: Predict Lab of Origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70553f4",
   "metadata": {},
   "source": [
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4674bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "from typing import *\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "#from sklearn.manifold import TSNE\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from yellowbrick.features import Manifold\n",
    "from yellowbrick.cluster import KElbowVisualizer, InterclusterDistance, SilhouetteVisualizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from altlabs.index_mapping import create_index_mapping\n",
    "from altlabs.dataset import (\n",
    "    noop,\n",
    "    random_roll,\n",
    "    _convert_to_indices,\n",
    "    SoftmaxDataset,\n",
    "    limit_sequence_size,\n",
    "    get_random_piece,\n",
    "    FactorizationDataset,\n",
    ")\n",
    "from altlabs.torch.data import FasterBatchSampler, NoAutoCollationDataLoader\n",
    "from altlabs.utils import Pipeline\n",
    "from pytorch_lightning import seed_everything\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd266b",
   "metadata": {},
   "source": [
    "### 2. Load model(s)\n",
    "- CNN + softmax\n",
    "- CNN + Triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d0c26f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stripping - WARNING - Not using Catalysis: No module named 'catalysis'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/yihliu/MLinPharma/capsule-3003146/code/altlabs/dataset.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  self._sequences = np.array([np.array(s) for s in self._sequences])\n",
      "/cluster/project/treutlein/USERS/yihliu/miniconda3/envs/altlabs/lib/python3.7/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/cluster/project/treutlein/USERS/yihliu/miniconda3/envs/altlabs/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.2 s, sys: 180 ms, total: 21.4 s\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "softmax_model_paths = list(sorted(glob(\"../data/output/56836160-1c29-4909-814d-b37d77e86ffc/tensorboard_logs_csv_logs/*/checkpoints/*.ckpt\")))\n",
    "lab_index_mapping_paths = list(sorted(glob(\"../data/output/56836160-1c29-4909-814d-b37d77e86ffc/tensorboard_logs_csv_logs/*/lab_index_mapping.pkl\")))\n",
    "# from altlabs.model.conv1d_attn_softmax_classifier import Conv1dAttnSoftmaxClassifier, ModelConfig\n",
    "# for loading the mode, we need to move .au directory to the root path of git which is capsule-3003146\n",
    "from altlabs.model.conv1d_attn_softmax_classifier import Conv1dAttnSoftmaxClassifier, ModelConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4898994a",
   "metadata": {},
   "source": [
    "### 3. Set data and results paths and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caabdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "RESULTS_PATH = \"../results/\"\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "train_values_df = pd.read_csv(f\"{DATA_PATH}train_values_grouped.csv\")\n",
    "train_labels_df = pd.read_csv(f\"{DATA_PATH}train_labels.csv\")\n",
    "format_df = pd.read_csv(f\"{DATA_PATH}format.csv\")\n",
    "test_values_df = pd.read_csv(f\"{DATA_PATH}test_values.csv\")\n",
    "test_set = pd.read_csv(f\"{DATA_PATH}test_labels.csv\")\n",
    "pub_id = pd.read_csv(f\"{DATA_PATH}pubsubidx.csv\")\n",
    "\n",
    "pub_index = pub_id[pub_id.public==True].index\n",
    "private_index = pub_id[pub_id.public==False].index\n",
    "\n",
    "# sample the data for prediction\n",
    "sample_size = 20\n",
    "# sample_frac = 0.01\n",
    "test_values_df_sampled = test_values_df.sample(sample_size,random_state=1)\n",
    "test_set_sampled = test_set.iloc[test_values_df_sampled.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad196512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>bacterial_resistance_ampicillin</th>\n",
       "      <th>bacterial_resistance_chloramphenicol</th>\n",
       "      <th>bacterial_resistance_kanamycin</th>\n",
       "      <th>bacterial_resistance_other</th>\n",
       "      <th>bacterial_resistance_spectinomycin</th>\n",
       "      <th>copy_number_high_copy</th>\n",
       "      <th>copy_number_low_copy</th>\n",
       "      <th>copy_number_unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>species_budding_yeast</th>\n",
       "      <th>species_fly</th>\n",
       "      <th>species_human</th>\n",
       "      <th>species_mouse</th>\n",
       "      <th>species_mustard_weed</th>\n",
       "      <th>species_nematode</th>\n",
       "      <th>species_other</th>\n",
       "      <th>species_rat</th>\n",
       "      <th>species_synthetic</th>\n",
       "      <th>species_zebrafish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8562</th>\n",
       "      <td>763Q6</td>\n",
       "      <td>CCTTCGGGCTTGTTAGCAGCCGGATCTCAGTGGTGGTGGTGGTGGT...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9594</th>\n",
       "      <td>H91R5</td>\n",
       "      <td>CTCTCTGGCTAACTAGAGAACCCACTGCTTACTGGCTTATCGAAAT...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>1LPO6</td>\n",
       "      <td>CTAAATTGTAAGCGTTAATATTTTGTTAAAATTCGCGTTAAATTTT...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>7D1UE</td>\n",
       "      <td>AGGTGAGCCAGTGAGTTGATTGCAGTCCAGTTACGCTGGAGTCTGA...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9692</th>\n",
       "      <td>08XBW</td>\n",
       "      <td>GCGCCACTTCTAAATAAGCGAATTTCTTATGATTTATGATTTTTAT...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>CG16U</td>\n",
       "      <td>TAATGTGAGTTAGCTCACTCATTAGGCACCCCAGGCTTTACACTTT...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18238</th>\n",
       "      <td>4YXP2</td>\n",
       "      <td>GGCAGTTCCCTACTCTCGCGTTAACGCTAGCATGGATGTTTTCCCA...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8213</th>\n",
       "      <td>7FJ8M</td>\n",
       "      <td>AATAAATTTCCTTTATTAGCCAGAAGTCAGATGCTCAAGGGGCTTC...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>M554J</td>\n",
       "      <td>CCGTCAGATCCGCTAGCGCTACCGGACTCAGATCTGGTACCCCTTG...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18399</th>\n",
       "      <td>MQH8S</td>\n",
       "      <td>TAGAGCTAGAAATAGCAAGTTAAAATAAGGCTAGTCCGTTATCAAC...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15291</th>\n",
       "      <td>2HVDU</td>\n",
       "      <td>GAACGATCCGCTGTTCCAGTCAATCAGGGTATTGAAGCTCATGGTC...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>LA0HH</td>\n",
       "      <td>AATGTGAGACCACGAAGTGGCTCTTCAGTGGACGAAAGGGCCTCGT...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>QULR5</td>\n",
       "      <td>GTCAGTGAGCGAGGAAGCGGAAGAGCGCCCAATACGCAAACCGCCT...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15804</th>\n",
       "      <td>TZ34K</td>\n",
       "      <td>TGATTGCAGTCCAGTTACGCTGGAGTCTGAGGCTCGTCCTGAATGA...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>721FI</td>\n",
       "      <td>GGTACCGAGCTCTTACGCGTGCTAGCCATACTATCAGCCACTTGTG...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9RGSY</td>\n",
       "      <td>GAGTCACTACCTGCCGATCACTCGCACCTTGGGTTTTGTTCCGATT...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16244</th>\n",
       "      <td>AHNTB</td>\n",
       "      <td>GGGCCAGGTTTCCGGGCCCTCACATTGCCAAAAGACGGCAATATGG...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>COADJ</td>\n",
       "      <td>CTGCAGCCTGAATATGGGCCAAACAGGATATCTGTGGTAAGCAGTT...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>VDOH2</td>\n",
       "      <td>GGTGTGCGTCACCCGGCAACCTTGGGTAGCAGCGAAGTCGAGGCAT...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16520</th>\n",
       "      <td>I56UC</td>\n",
       "      <td>GGTGGAGCCGGTGGAGCCGGTGGAGCCGAATTCCGAGATGGTCTGA...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sequence_id                                           sequence  \\\n",
       "8562        763Q6  CCTTCGGGCTTGTTAGCAGCCGGATCTCAGTGGTGGTGGTGGTGGT...   \n",
       "9594        H91R5  CTCTCTGGCTAACTAGAGAACCCACTGCTTACTGGCTTATCGAAAT...   \n",
       "7025        1LPO6  CTAAATTGTAAGCGTTAATATTTTGTTAAAATTCGCGTTAAATTTT...   \n",
       "2012        7D1UE  AGGTGAGCCAGTGAGTTGATTGCAGTCCAGTTACGCTGGAGTCTGA...   \n",
       "9692        08XBW  GCGCCACTTCTAAATAAGCGAATTTCTTATGATTTATGATTTTTAT...   \n",
       "15071       CG16U  TAATGTGAGTTAGCTCACTCATTAGGCACCCCAGGCTTTACACTTT...   \n",
       "18238       4YXP2  GGCAGTTCCCTACTCTCGCGTTAACGCTAGCATGGATGTTTTCCCA...   \n",
       "8213        7FJ8M  AATAAATTTCCTTTATTAGCCAGAAGTCAGATGCTCAAGGGGCTTC...   \n",
       "620         M554J  CCGTCAGATCCGCTAGCGCTACCGGACTCAGATCTGGTACCCCTTG...   \n",
       "18399       MQH8S  TAGAGCTAGAAATAGCAAGTTAAAATAAGGCTAGTCCGTTATCAAC...   \n",
       "15291       2HVDU  GAACGATCCGCTGTTCCAGTCAATCAGGGTATTGAAGCTCATGGTC...   \n",
       "993         LA0HH  AATGTGAGACCACGAAGTGGCTCTTCAGTGGACGAAAGGGCCTCGT...   \n",
       "5659        QULR5  GTCAGTGAGCGAGGAAGCGGAAGAGCGCCCAATACGCAAACCGCCT...   \n",
       "15804       TZ34K  TGATTGCAGTCCAGTTACGCTGGAGTCTGAGGCTCGTCCTGAATGA...   \n",
       "4           721FI  GGTACCGAGCTCTTACGCGTGCTAGCCATACTATCAGCCACTTGTG...   \n",
       "8688        9RGSY  GAGTCACTACCTGCCGATCACTCGCACCTTGGGTTTTGTTCCGATT...   \n",
       "16244       AHNTB  GGGCCAGGTTTCCGGGCCCTCACATTGCCAAAAGACGGCAATATGG...   \n",
       "14635       COADJ  CTGCAGCCTGAATATGGGCCAAACAGGATATCTGTGGTAAGCAGTT...   \n",
       "5500        VDOH2  GGTGTGCGTCACCCGGCAACCTTGGGTAGCAGCGAAGTCGAGGCAT...   \n",
       "16520       I56UC  GGTGGAGCCGGTGGAGCCGGTGGAGCCGAATTCCGAGATGGTCTGA...   \n",
       "\n",
       "       bacterial_resistance_ampicillin  bacterial_resistance_chloramphenicol  \\\n",
       "8562                               1.0                                   0.0   \n",
       "9594                               1.0                                   0.0   \n",
       "7025                               1.0                                   0.0   \n",
       "2012                               0.0                                   0.0   \n",
       "9692                               1.0                                   0.0   \n",
       "15071                              1.0                                   0.0   \n",
       "18238                              0.0                                   0.0   \n",
       "8213                               1.0                                   0.0   \n",
       "620                                0.0                                   0.0   \n",
       "18399                              1.0                                   0.0   \n",
       "15291                              1.0                                   0.0   \n",
       "993                                0.0                                   0.0   \n",
       "5659                               0.0                                   0.0   \n",
       "15804                              0.0                                   0.0   \n",
       "4                                  1.0                                   0.0   \n",
       "8688                               1.0                                   0.0   \n",
       "16244                              0.0                                   0.0   \n",
       "14635                              1.0                                   0.0   \n",
       "5500                               0.0                                   0.0   \n",
       "16520                              0.0                                   0.0   \n",
       "\n",
       "       bacterial_resistance_kanamycin  bacterial_resistance_other  \\\n",
       "8562                              0.0                         0.0   \n",
       "9594                              0.0                         0.0   \n",
       "7025                              0.0                         0.0   \n",
       "2012                              1.0                         0.0   \n",
       "9692                              0.0                         0.0   \n",
       "15071                             0.0                         0.0   \n",
       "18238                             0.0                         0.0   \n",
       "8213                              0.0                         0.0   \n",
       "620                               1.0                         0.0   \n",
       "18399                             0.0                         0.0   \n",
       "15291                             0.0                         0.0   \n",
       "993                               0.0                         0.0   \n",
       "5659                              1.0                         0.0   \n",
       "15804                             1.0                         0.0   \n",
       "4                                 0.0                         0.0   \n",
       "8688                              0.0                         0.0   \n",
       "16244                             1.0                         0.0   \n",
       "14635                             0.0                         0.0   \n",
       "5500                              0.0                         0.0   \n",
       "16520                             1.0                         0.0   \n",
       "\n",
       "       bacterial_resistance_spectinomycin  copy_number_high_copy  \\\n",
       "8562                                  0.0                    0.0   \n",
       "9594                                  0.0                    0.0   \n",
       "7025                                  0.0                    1.0   \n",
       "2012                                  0.0                    0.0   \n",
       "9692                                  0.0                    0.0   \n",
       "15071                                 0.0                    1.0   \n",
       "18238                                 1.0                    1.0   \n",
       "8213                                  0.0                    1.0   \n",
       "620                                   0.0                    1.0   \n",
       "18399                                 0.0                    1.0   \n",
       "15291                                 0.0                    0.0   \n",
       "993                                   1.0                    1.0   \n",
       "5659                                  0.0                    1.0   \n",
       "15804                                 0.0                    1.0   \n",
       "4                                     0.0                    1.0   \n",
       "8688                                  0.0                    1.0   \n",
       "16244                                 0.0                    0.0   \n",
       "14635                                 0.0                    1.0   \n",
       "5500                                  1.0                    1.0   \n",
       "16520                                 0.0                    1.0   \n",
       "\n",
       "       copy_number_low_copy  copy_number_unknown  ...  species_budding_yeast  \\\n",
       "8562                    1.0                  0.0  ...                    1.0   \n",
       "9594                    1.0                  0.0  ...                    0.0   \n",
       "7025                    0.0                  0.0  ...                    0.0   \n",
       "2012                    0.0                  1.0  ...                    0.0   \n",
       "9692                    0.0                  1.0  ...                    0.0   \n",
       "15071                   0.0                  0.0  ...                    0.0   \n",
       "18238                   0.0                  0.0  ...                    0.0   \n",
       "8213                    0.0                  0.0  ...                    0.0   \n",
       "620                     0.0                  0.0  ...                    0.0   \n",
       "18399                   0.0                  0.0  ...                    0.0   \n",
       "15291                   0.0                  1.0  ...                    0.0   \n",
       "993                     0.0                  0.0  ...                    0.0   \n",
       "5659                    0.0                  0.0  ...                    0.0   \n",
       "15804                   0.0                  0.0  ...                    0.0   \n",
       "4                       0.0                  0.0  ...                    0.0   \n",
       "8688                    0.0                  0.0  ...                    0.0   \n",
       "16244                   0.0                  1.0  ...                    0.0   \n",
       "14635                   0.0                  0.0  ...                    0.0   \n",
       "5500                    0.0                  0.0  ...                    0.0   \n",
       "16520                   0.0                  0.0  ...                    0.0   \n",
       "\n",
       "       species_fly  species_human  species_mouse  species_mustard_weed  \\\n",
       "8562           0.0            0.0            0.0                   0.0   \n",
       "9594           0.0            0.0            0.0                   0.0   \n",
       "7025           0.0            0.0            0.0                   0.0   \n",
       "2012           0.0            0.0            0.0                   0.0   \n",
       "9692           0.0            0.0            0.0                   0.0   \n",
       "15071          0.0            0.0            0.0                   0.0   \n",
       "18238          0.0            1.0            0.0                   0.0   \n",
       "8213           0.0            0.0            1.0                   0.0   \n",
       "620            0.0            0.0            0.0                   0.0   \n",
       "18399          0.0            1.0            0.0                   0.0   \n",
       "15291          0.0            0.0            0.0                   0.0   \n",
       "993            0.0            0.0            0.0                   0.0   \n",
       "5659           0.0            0.0            0.0                   0.0   \n",
       "15804          0.0            0.0            0.0                   0.0   \n",
       "4              0.0            1.0            0.0                   0.0   \n",
       "8688           0.0            0.0            0.0                   0.0   \n",
       "16244          0.0            0.0            0.0                   0.0   \n",
       "14635          0.0            1.0            0.0                   0.0   \n",
       "5500           0.0            0.0            0.0                   0.0   \n",
       "16520          0.0            0.0            0.0                   0.0   \n",
       "\n",
       "       species_nematode  species_other  species_rat  species_synthetic  \\\n",
       "8562                0.0            0.0          0.0                0.0   \n",
       "9594                0.0            0.0          0.0                0.0   \n",
       "7025                0.0            1.0          0.0                0.0   \n",
       "2012                0.0            1.0          0.0                0.0   \n",
       "9692                0.0            0.0          0.0                1.0   \n",
       "15071               0.0            0.0          0.0                0.0   \n",
       "18238               0.0            0.0          0.0                0.0   \n",
       "8213                0.0            0.0          0.0                0.0   \n",
       "620                 0.0            0.0          0.0                0.0   \n",
       "18399               0.0            0.0          0.0                0.0   \n",
       "15291               0.0            0.0          0.0                0.0   \n",
       "993                 0.0            0.0          0.0                0.0   \n",
       "5659                0.0            0.0          0.0                1.0   \n",
       "15804               0.0            0.0          0.0                1.0   \n",
       "4                   0.0            0.0          0.0                0.0   \n",
       "8688                0.0            1.0          0.0                0.0   \n",
       "16244               0.0            0.0          0.0                1.0   \n",
       "14635               0.0            0.0          0.0                0.0   \n",
       "5500                0.0            0.0          0.0                1.0   \n",
       "16520               0.0            0.0          1.0                0.0   \n",
       "\n",
       "       species_zebrafish  \n",
       "8562                 0.0  \n",
       "9594                 0.0  \n",
       "7025                 0.0  \n",
       "2012                 0.0  \n",
       "9692                 0.0  \n",
       "15071                0.0  \n",
       "18238                0.0  \n",
       "8213                 0.0  \n",
       "620                  0.0  \n",
       "18399                0.0  \n",
       "15291                0.0  \n",
       "993                  0.0  \n",
       "5659                 0.0  \n",
       "15804                0.0  \n",
       "4                    0.0  \n",
       "8688                 0.0  \n",
       "16244                0.0  \n",
       "14635                0.0  \n",
       "5500                 0.0  \n",
       "16520                0.0  \n",
       "\n",
       "[20 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show input\n",
    "test_values_df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0c347",
   "metadata": {},
   "source": [
    "### 4. Data preprocesse\n",
    "delete labs if there are less than 1 sequence belonging to them in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "becff384",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_sequence_fn = Pipeline(\n",
    "    random_roll,\n",
    "    functools.partial(limit_sequence_size, limit=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aab0ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_index_mapping = create_index_mapping(\n",
    "    \"ATGC\", include_unkown=True, include_none=False,\n",
    ")\n",
    "sequence_index_mapping[\"N\"] = 0\n",
    "\n",
    "input_columns = train_values_df.drop(columns=[\"sequence_id\", \"groups\", \"output\"]).columns\n",
    "output_columns = train_labels_df.drop(columns=[\"sequence_id\"]).columns\n",
    "occurrences = np.sum(train_labels_df[output_columns].values, axis=0)\n",
    "minimum_occurrences = 1\n",
    "filtered_out_output_columns = output_columns[\n",
    "    occurrences < minimum_occurrences\n",
    "]\n",
    "output_columns = output_columns.drop(filtered_out_output_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72030e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered_out_labs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filtered_out_labs]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show filled out labs (you can increase the minimum_occurences)\n",
    "# thinking about achieving it in an interactive way\n",
    "fooc = pd.DataFrame(filtered_out_output_columns)\n",
    "fooc.rename(columns={0:'filtered_out_labs'}, inplace=True)\n",
    "fooc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b2c57",
   "metadata": {},
   "source": [
    "### 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "975bd2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(350)\n",
    "\n",
    "def predict_dataset(model: Conv1dAttnSoftmaxClassifier, dataset: FactorizationDataset, tta_steps: int) -> np.ndarray:\n",
    "    batch_sampler = FasterBatchSampler(\n",
    "        dataset, 32, shuffle=False,\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    predictions: List[List[float]] = []\n",
    "    with torch.no_grad():\n",
    "        for indices in batch_sampler:\n",
    "            if tta_steps > 0:\n",
    "                tta_predictions = []\n",
    "                for i in range(tta_steps):\n",
    "                    batch = dataset[indices]\n",
    "                    if isinstance(batch[0], tuple):\n",
    "                        (sequences, extra_inputs, _) = batch[\n",
    "                            0\n",
    "                        ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "                    else:\n",
    "                        (sequences, extra_inputs) = batch\n",
    "                    outputs = torch.nn.functional.softmax(model(\n",
    "                        sequences.to(device), extra_inputs.to(device)\n",
    "                    )).tolist()\n",
    "                    tta_predictions.append(np.array(outputs))\n",
    "                predictions.extend(\n",
    "                    np.mean(np.array(tta_predictions), axis=0).tolist()\n",
    "                )\n",
    "            else:\n",
    "                batch = dataset[indices]\n",
    "                if isinstance(batch[0], tuple):\n",
    "                    (sequences, extra_inputs, _) = batch[\n",
    "                        0\n",
    "                    ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "                else:\n",
    "                    (sequences, extra_inputs) = batch\n",
    "                outputs = torch.nn.functional.softmax(model(\n",
    "                    sequences.to(device), extra_inputs.to(device)\n",
    "                )).tolist()\n",
    "                predictions.extend(outputs)\n",
    "\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac7fa256",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/cluster/home/yihliu/MLinPharma/capsule-3003146/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86d75707",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fold_output = []\n",
    "for softmax_model_path in softmax_model_paths:\n",
    "    model = Conv1dAttnSoftmaxClassifier.load_from_checkpoint(softmax_model_path)\n",
    "    model.model_config.positional_encoding = True\n",
    "    \n",
    "    dataset = SoftmaxDataset(\n",
    "        test_values_df_sampled, # only for the showcase, for the exact resulst replace it with test_values_df\n",
    "        sequence_index_mapping,\n",
    "        input_columns,\n",
    "        transform_sequence_fn=transform_sequence_fn,\n",
    "        test=True,\n",
    "        bpe=True,\n",
    "    )\n",
    "    outputs = predict_dataset(model, dataset, 10)\n",
    "    fold_output.append(outputs)\n",
    "final_outputs = np.mean(fold_output, axis=0)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=final_outputs, columns=output_columns, index=test_values_df_sampled[\"sequence_id\"]\n",
    ")\n",
    "\n",
    "\n",
    "for column in filtered_out_output_columns:\n",
    "    df[column] = 0.0\n",
    "df = df[format_df.drop(columns=[\"sequence_id\"]).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fad8560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate softmax output for pub and private sub sets\n",
    "df = df.reset_index()\n",
    "df.index = test_values_df_sampled.index\n",
    "pub_best_sub = df[df.index.isin(pub_index)]\n",
    "private_best_sub = df[df.index.isin(private_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abd9ca0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>00Q4V31T</th>\n",
       "      <th>012VT4JK</th>\n",
       "      <th>028IO5W2</th>\n",
       "      <th>03GRNN7N</th>\n",
       "      <th>03Y3W51H</th>\n",
       "      <th>09MQV1TY</th>\n",
       "      <th>0A4AHRCT</th>\n",
       "      <th>0A9M05NC</th>\n",
       "      <th>0B9GCUVV</th>\n",
       "      <th>...</th>\n",
       "      <th>ZQNGGY33</th>\n",
       "      <th>ZSHS4VJZ</th>\n",
       "      <th>ZT1IP3T6</th>\n",
       "      <th>ZU6860XU</th>\n",
       "      <th>ZU6TVFFU</th>\n",
       "      <th>ZU75P59K</th>\n",
       "      <th>ZUI6TDWV</th>\n",
       "      <th>ZWFD8OHC</th>\n",
       "      <th>ZX06ZDZN</th>\n",
       "      <th>ZZJVE4HO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8562</th>\n",
       "      <td>763Q6</td>\n",
       "      <td>7.979069e-07</td>\n",
       "      <td>3.675521e-06</td>\n",
       "      <td>1.005988e-05</td>\n",
       "      <td>1.057913e-09</td>\n",
       "      <td>2.188058e-08</td>\n",
       "      <td>2.003484e-09</td>\n",
       "      <td>4.041081e-07</td>\n",
       "      <td>4.487104e-05</td>\n",
       "      <td>1.564062e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.095188e-09</td>\n",
       "      <td>2.696536e-07</td>\n",
       "      <td>5.698084e-06</td>\n",
       "      <td>3.874287e-08</td>\n",
       "      <td>1.595496e-07</td>\n",
       "      <td>1.010311e-09</td>\n",
       "      <td>3.371859e-08</td>\n",
       "      <td>1.439377e-09</td>\n",
       "      <td>4.872080e-08</td>\n",
       "      <td>5.264684e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9594</th>\n",
       "      <td>H91R5</td>\n",
       "      <td>6.318677e-07</td>\n",
       "      <td>1.818296e-05</td>\n",
       "      <td>3.861178e-06</td>\n",
       "      <td>4.405780e-09</td>\n",
       "      <td>1.671208e-06</td>\n",
       "      <td>1.043394e-04</td>\n",
       "      <td>5.513840e-05</td>\n",
       "      <td>6.960503e-06</td>\n",
       "      <td>3.120395e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.186578e-07</td>\n",
       "      <td>2.978356e-06</td>\n",
       "      <td>2.222654e-06</td>\n",
       "      <td>1.647494e-06</td>\n",
       "      <td>3.371715e-06</td>\n",
       "      <td>3.072278e-09</td>\n",
       "      <td>1.336448e-07</td>\n",
       "      <td>5.312367e-09</td>\n",
       "      <td>2.790057e-04</td>\n",
       "      <td>1.313600e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>1LPO6</td>\n",
       "      <td>1.324063e-03</td>\n",
       "      <td>1.796431e-05</td>\n",
       "      <td>1.020560e-05</td>\n",
       "      <td>1.667350e-08</td>\n",
       "      <td>8.271114e-05</td>\n",
       "      <td>1.851370e-09</td>\n",
       "      <td>1.667703e-07</td>\n",
       "      <td>7.329797e-05</td>\n",
       "      <td>7.386574e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.809847e-06</td>\n",
       "      <td>3.824033e-06</td>\n",
       "      <td>4.119010e-07</td>\n",
       "      <td>6.303115e-08</td>\n",
       "      <td>1.007823e-05</td>\n",
       "      <td>2.838526e-09</td>\n",
       "      <td>2.661973e-04</td>\n",
       "      <td>1.807503e-05</td>\n",
       "      <td>1.281278e-04</td>\n",
       "      <td>4.924133e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>7D1UE</td>\n",
       "      <td>1.626151e-07</td>\n",
       "      <td>2.463091e-08</td>\n",
       "      <td>1.087462e-08</td>\n",
       "      <td>4.609434e-11</td>\n",
       "      <td>1.096995e-05</td>\n",
       "      <td>1.725652e-07</td>\n",
       "      <td>4.701513e-09</td>\n",
       "      <td>6.949667e-08</td>\n",
       "      <td>7.127944e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.073851e-08</td>\n",
       "      <td>4.728307e-06</td>\n",
       "      <td>5.706815e-08</td>\n",
       "      <td>6.395503e-10</td>\n",
       "      <td>2.369316e-04</td>\n",
       "      <td>1.449478e-07</td>\n",
       "      <td>1.065736e-06</td>\n",
       "      <td>2.320280e-09</td>\n",
       "      <td>1.875290e-06</td>\n",
       "      <td>6.304308e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9692</th>\n",
       "      <td>08XBW</td>\n",
       "      <td>8.689943e-07</td>\n",
       "      <td>1.883846e-06</td>\n",
       "      <td>3.544023e-07</td>\n",
       "      <td>2.770014e-11</td>\n",
       "      <td>1.706118e-05</td>\n",
       "      <td>3.210669e-06</td>\n",
       "      <td>3.694428e-06</td>\n",
       "      <td>6.799489e-05</td>\n",
       "      <td>1.037957e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>6.522609e-06</td>\n",
       "      <td>1.101537e-07</td>\n",
       "      <td>4.936313e-08</td>\n",
       "      <td>2.196971e-07</td>\n",
       "      <td>3.247159e-05</td>\n",
       "      <td>3.236089e-09</td>\n",
       "      <td>5.265978e-06</td>\n",
       "      <td>1.915174e-07</td>\n",
       "      <td>3.581877e-09</td>\n",
       "      <td>2.703873e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>CG16U</td>\n",
       "      <td>6.488553e-04</td>\n",
       "      <td>2.979651e-03</td>\n",
       "      <td>2.338993e-04</td>\n",
       "      <td>2.614100e-05</td>\n",
       "      <td>2.950619e-04</td>\n",
       "      <td>2.689785e-07</td>\n",
       "      <td>1.130019e-07</td>\n",
       "      <td>1.237655e-04</td>\n",
       "      <td>1.530813e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.963289e-05</td>\n",
       "      <td>1.215044e-05</td>\n",
       "      <td>1.946164e-04</td>\n",
       "      <td>7.135100e-04</td>\n",
       "      <td>1.328416e-04</td>\n",
       "      <td>7.727913e-08</td>\n",
       "      <td>5.883546e-04</td>\n",
       "      <td>2.205955e-04</td>\n",
       "      <td>1.709917e-04</td>\n",
       "      <td>3.826671e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18238</th>\n",
       "      <td>4YXP2</td>\n",
       "      <td>3.949295e-06</td>\n",
       "      <td>3.121237e-06</td>\n",
       "      <td>4.620568e-07</td>\n",
       "      <td>2.926456e-06</td>\n",
       "      <td>2.276023e-06</td>\n",
       "      <td>7.261931e-09</td>\n",
       "      <td>1.323213e-08</td>\n",
       "      <td>1.236932e-06</td>\n",
       "      <td>9.750028e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.013361e-04</td>\n",
       "      <td>1.382394e-07</td>\n",
       "      <td>3.906809e-05</td>\n",
       "      <td>1.596386e-08</td>\n",
       "      <td>2.422226e-07</td>\n",
       "      <td>3.191004e-06</td>\n",
       "      <td>1.098435e-08</td>\n",
       "      <td>6.037899e-06</td>\n",
       "      <td>5.767361e-08</td>\n",
       "      <td>2.016064e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8213</th>\n",
       "      <td>7FJ8M</td>\n",
       "      <td>5.251613e-05</td>\n",
       "      <td>5.154832e-05</td>\n",
       "      <td>2.743568e-03</td>\n",
       "      <td>6.019946e-05</td>\n",
       "      <td>1.684182e-04</td>\n",
       "      <td>8.228342e-07</td>\n",
       "      <td>2.853927e-08</td>\n",
       "      <td>1.049513e-04</td>\n",
       "      <td>1.879991e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.742810e-05</td>\n",
       "      <td>7.230655e-07</td>\n",
       "      <td>2.311679e-04</td>\n",
       "      <td>1.029956e-06</td>\n",
       "      <td>1.893149e-07</td>\n",
       "      <td>1.277094e-08</td>\n",
       "      <td>2.825465e-06</td>\n",
       "      <td>5.380128e-05</td>\n",
       "      <td>4.222040e-06</td>\n",
       "      <td>1.447473e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>M554J</td>\n",
       "      <td>3.279212e-09</td>\n",
       "      <td>3.075777e-06</td>\n",
       "      <td>2.009316e-09</td>\n",
       "      <td>1.076668e-04</td>\n",
       "      <td>3.635616e-04</td>\n",
       "      <td>1.076119e-07</td>\n",
       "      <td>1.189297e-08</td>\n",
       "      <td>3.461129e-09</td>\n",
       "      <td>1.597586e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.254928e-07</td>\n",
       "      <td>3.300600e-06</td>\n",
       "      <td>1.539989e-04</td>\n",
       "      <td>6.316188e-07</td>\n",
       "      <td>5.772490e-06</td>\n",
       "      <td>3.032196e-06</td>\n",
       "      <td>4.374311e-09</td>\n",
       "      <td>5.986251e-09</td>\n",
       "      <td>5.254447e-06</td>\n",
       "      <td>1.378214e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18399</th>\n",
       "      <td>MQH8S</td>\n",
       "      <td>9.133222e-05</td>\n",
       "      <td>1.673103e-05</td>\n",
       "      <td>4.680719e-05</td>\n",
       "      <td>4.905937e-05</td>\n",
       "      <td>5.950133e-05</td>\n",
       "      <td>4.967139e-08</td>\n",
       "      <td>2.247101e-07</td>\n",
       "      <td>1.163712e-04</td>\n",
       "      <td>1.068975e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.012733e-04</td>\n",
       "      <td>1.043876e-06</td>\n",
       "      <td>6.470869e-04</td>\n",
       "      <td>3.620759e-07</td>\n",
       "      <td>1.840537e-07</td>\n",
       "      <td>1.389077e-09</td>\n",
       "      <td>2.058312e-07</td>\n",
       "      <td>8.195628e-04</td>\n",
       "      <td>3.422509e-07</td>\n",
       "      <td>1.688624e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15291</th>\n",
       "      <td>2HVDU</td>\n",
       "      <td>1.649451e-08</td>\n",
       "      <td>1.106213e-06</td>\n",
       "      <td>1.204061e-08</td>\n",
       "      <td>9.324305e-12</td>\n",
       "      <td>1.172222e-07</td>\n",
       "      <td>9.643852e-07</td>\n",
       "      <td>1.020926e-06</td>\n",
       "      <td>4.185727e-07</td>\n",
       "      <td>5.376048e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.760874e-07</td>\n",
       "      <td>6.894687e-09</td>\n",
       "      <td>1.229060e-07</td>\n",
       "      <td>1.473739e-06</td>\n",
       "      <td>1.470544e-04</td>\n",
       "      <td>2.111852e-09</td>\n",
       "      <td>9.235870e-06</td>\n",
       "      <td>5.243374e-09</td>\n",
       "      <td>4.289754e-09</td>\n",
       "      <td>4.009480e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>LA0HH</td>\n",
       "      <td>1.404283e-06</td>\n",
       "      <td>2.156930e-05</td>\n",
       "      <td>3.088006e-07</td>\n",
       "      <td>2.069963e-07</td>\n",
       "      <td>7.783605e-07</td>\n",
       "      <td>2.874742e-08</td>\n",
       "      <td>7.552820e-08</td>\n",
       "      <td>5.392986e-08</td>\n",
       "      <td>8.740805e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.376041e-06</td>\n",
       "      <td>2.378619e-04</td>\n",
       "      <td>1.139918e-06</td>\n",
       "      <td>7.784023e-07</td>\n",
       "      <td>1.227150e-05</td>\n",
       "      <td>6.533272e-05</td>\n",
       "      <td>4.506002e-07</td>\n",
       "      <td>7.060590e-08</td>\n",
       "      <td>4.375961e-06</td>\n",
       "      <td>3.663925e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>QULR5</td>\n",
       "      <td>1.120746e-07</td>\n",
       "      <td>1.581335e-06</td>\n",
       "      <td>6.039502e-08</td>\n",
       "      <td>1.264729e-07</td>\n",
       "      <td>1.411989e-03</td>\n",
       "      <td>1.827057e-08</td>\n",
       "      <td>2.263319e-09</td>\n",
       "      <td>3.262612e-07</td>\n",
       "      <td>1.144319e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.292289e-06</td>\n",
       "      <td>1.017459e-05</td>\n",
       "      <td>4.486286e-07</td>\n",
       "      <td>3.695173e-09</td>\n",
       "      <td>1.410119e-05</td>\n",
       "      <td>6.299644e-07</td>\n",
       "      <td>2.257600e-08</td>\n",
       "      <td>6.167449e-09</td>\n",
       "      <td>6.324326e-07</td>\n",
       "      <td>1.199149e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15804</th>\n",
       "      <td>TZ34K</td>\n",
       "      <td>3.822815e-08</td>\n",
       "      <td>6.736476e-07</td>\n",
       "      <td>1.008335e-07</td>\n",
       "      <td>5.998432e-08</td>\n",
       "      <td>1.753323e-03</td>\n",
       "      <td>6.695667e-09</td>\n",
       "      <td>9.973665e-10</td>\n",
       "      <td>4.352957e-07</td>\n",
       "      <td>1.340078e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.279577e-06</td>\n",
       "      <td>5.146978e-06</td>\n",
       "      <td>2.334620e-07</td>\n",
       "      <td>1.474327e-09</td>\n",
       "      <td>9.122199e-06</td>\n",
       "      <td>4.641185e-07</td>\n",
       "      <td>9.350890e-09</td>\n",
       "      <td>2.217516e-09</td>\n",
       "      <td>2.615995e-07</td>\n",
       "      <td>4.557814e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>721FI</td>\n",
       "      <td>4.317657e-05</td>\n",
       "      <td>1.070429e-05</td>\n",
       "      <td>2.139072e-05</td>\n",
       "      <td>1.073118e-05</td>\n",
       "      <td>4.914369e-04</td>\n",
       "      <td>2.590927e-08</td>\n",
       "      <td>4.647548e-08</td>\n",
       "      <td>3.966734e-05</td>\n",
       "      <td>6.949041e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.304608e-04</td>\n",
       "      <td>5.380421e-07</td>\n",
       "      <td>2.087675e-04</td>\n",
       "      <td>1.990637e-07</td>\n",
       "      <td>9.806715e-08</td>\n",
       "      <td>7.039285e-10</td>\n",
       "      <td>1.078667e-07</td>\n",
       "      <td>3.371315e-04</td>\n",
       "      <td>1.739712e-07</td>\n",
       "      <td>8.369440e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9RGSY</td>\n",
       "      <td>3.683065e-03</td>\n",
       "      <td>7.354750e-05</td>\n",
       "      <td>3.560518e-05</td>\n",
       "      <td>5.221055e-08</td>\n",
       "      <td>5.066686e-05</td>\n",
       "      <td>3.239617e-08</td>\n",
       "      <td>7.286828e-09</td>\n",
       "      <td>1.953560e-04</td>\n",
       "      <td>5.644220e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.478052e-06</td>\n",
       "      <td>1.511690e-05</td>\n",
       "      <td>1.134609e-06</td>\n",
       "      <td>4.078442e-07</td>\n",
       "      <td>4.091639e-05</td>\n",
       "      <td>1.652965e-08</td>\n",
       "      <td>1.033150e-03</td>\n",
       "      <td>4.969766e-05</td>\n",
       "      <td>3.294564e-04</td>\n",
       "      <td>5.680109e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16244</th>\n",
       "      <td>AHNTB</td>\n",
       "      <td>5.641113e-11</td>\n",
       "      <td>9.785084e-09</td>\n",
       "      <td>1.904524e-11</td>\n",
       "      <td>3.540081e-10</td>\n",
       "      <td>7.041827e-05</td>\n",
       "      <td>1.731204e-06</td>\n",
       "      <td>5.694755e-07</td>\n",
       "      <td>1.082970e-08</td>\n",
       "      <td>1.512749e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.315825e-08</td>\n",
       "      <td>7.297703e-08</td>\n",
       "      <td>1.210503e-07</td>\n",
       "      <td>2.873316e-10</td>\n",
       "      <td>3.803409e-06</td>\n",
       "      <td>1.270492e-07</td>\n",
       "      <td>1.812805e-10</td>\n",
       "      <td>2.399371e-11</td>\n",
       "      <td>1.382957e-10</td>\n",
       "      <td>1.353358e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>COADJ</td>\n",
       "      <td>3.695506e-07</td>\n",
       "      <td>2.739378e-07</td>\n",
       "      <td>1.719580e-07</td>\n",
       "      <td>1.005805e-04</td>\n",
       "      <td>2.917075e-06</td>\n",
       "      <td>1.005361e-08</td>\n",
       "      <td>1.591131e-07</td>\n",
       "      <td>8.513446e-07</td>\n",
       "      <td>1.916757e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.663804e-04</td>\n",
       "      <td>4.207964e-08</td>\n",
       "      <td>3.410388e-04</td>\n",
       "      <td>1.347353e-08</td>\n",
       "      <td>6.088542e-09</td>\n",
       "      <td>1.909283e-10</td>\n",
       "      <td>1.241285e-08</td>\n",
       "      <td>8.412393e-07</td>\n",
       "      <td>1.228447e-08</td>\n",
       "      <td>3.188349e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>VDOH2</td>\n",
       "      <td>1.752586e-06</td>\n",
       "      <td>1.036753e-05</td>\n",
       "      <td>2.389750e-07</td>\n",
       "      <td>4.506318e-09</td>\n",
       "      <td>4.437590e-05</td>\n",
       "      <td>1.255074e-08</td>\n",
       "      <td>1.608026e-08</td>\n",
       "      <td>5.178069e-06</td>\n",
       "      <td>3.570240e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.410687e-05</td>\n",
       "      <td>3.183095e-07</td>\n",
       "      <td>9.348541e-08</td>\n",
       "      <td>5.418517e-08</td>\n",
       "      <td>2.442954e-05</td>\n",
       "      <td>3.115276e-05</td>\n",
       "      <td>7.324467e-07</td>\n",
       "      <td>5.949491e-08</td>\n",
       "      <td>1.205146e-07</td>\n",
       "      <td>5.385205e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16520</th>\n",
       "      <td>I56UC</td>\n",
       "      <td>1.016993e-15</td>\n",
       "      <td>1.910037e-15</td>\n",
       "      <td>1.271685e-15</td>\n",
       "      <td>4.605314e-11</td>\n",
       "      <td>9.715478e-08</td>\n",
       "      <td>3.474597e-12</td>\n",
       "      <td>5.137770e-13</td>\n",
       "      <td>1.054089e-11</td>\n",
       "      <td>1.460893e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.783351e-13</td>\n",
       "      <td>2.942059e-12</td>\n",
       "      <td>1.059169e-09</td>\n",
       "      <td>5.956728e-14</td>\n",
       "      <td>1.137713e-12</td>\n",
       "      <td>9.778938e-11</td>\n",
       "      <td>1.190961e-16</td>\n",
       "      <td>1.631349e-15</td>\n",
       "      <td>1.725162e-10</td>\n",
       "      <td>8.730035e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sequence_id      00Q4V31T      012VT4JK      028IO5W2      03GRNN7N  \\\n",
       "8562        763Q6  7.979069e-07  3.675521e-06  1.005988e-05  1.057913e-09   \n",
       "9594        H91R5  6.318677e-07  1.818296e-05  3.861178e-06  4.405780e-09   \n",
       "7025        1LPO6  1.324063e-03  1.796431e-05  1.020560e-05  1.667350e-08   \n",
       "2012        7D1UE  1.626151e-07  2.463091e-08  1.087462e-08  4.609434e-11   \n",
       "9692        08XBW  8.689943e-07  1.883846e-06  3.544023e-07  2.770014e-11   \n",
       "15071       CG16U  6.488553e-04  2.979651e-03  2.338993e-04  2.614100e-05   \n",
       "18238       4YXP2  3.949295e-06  3.121237e-06  4.620568e-07  2.926456e-06   \n",
       "8213        7FJ8M  5.251613e-05  5.154832e-05  2.743568e-03  6.019946e-05   \n",
       "620         M554J  3.279212e-09  3.075777e-06  2.009316e-09  1.076668e-04   \n",
       "18399       MQH8S  9.133222e-05  1.673103e-05  4.680719e-05  4.905937e-05   \n",
       "15291       2HVDU  1.649451e-08  1.106213e-06  1.204061e-08  9.324305e-12   \n",
       "993         LA0HH  1.404283e-06  2.156930e-05  3.088006e-07  2.069963e-07   \n",
       "5659        QULR5  1.120746e-07  1.581335e-06  6.039502e-08  1.264729e-07   \n",
       "15804       TZ34K  3.822815e-08  6.736476e-07  1.008335e-07  5.998432e-08   \n",
       "4           721FI  4.317657e-05  1.070429e-05  2.139072e-05  1.073118e-05   \n",
       "8688        9RGSY  3.683065e-03  7.354750e-05  3.560518e-05  5.221055e-08   \n",
       "16244       AHNTB  5.641113e-11  9.785084e-09  1.904524e-11  3.540081e-10   \n",
       "14635       COADJ  3.695506e-07  2.739378e-07  1.719580e-07  1.005805e-04   \n",
       "5500        VDOH2  1.752586e-06  1.036753e-05  2.389750e-07  4.506318e-09   \n",
       "16520       I56UC  1.016993e-15  1.910037e-15  1.271685e-15  4.605314e-11   \n",
       "\n",
       "           03Y3W51H      09MQV1TY      0A4AHRCT      0A9M05NC      0B9GCUVV  \\\n",
       "8562   2.188058e-08  2.003484e-09  4.041081e-07  4.487104e-05  1.564062e-02   \n",
       "9594   1.671208e-06  1.043394e-04  5.513840e-05  6.960503e-06  3.120395e-07   \n",
       "7025   8.271114e-05  1.851370e-09  1.667703e-07  7.329797e-05  7.386574e-05   \n",
       "2012   1.096995e-05  1.725652e-07  4.701513e-09  6.949667e-08  7.127944e-04   \n",
       "9692   1.706118e-05  3.210669e-06  3.694428e-06  6.799489e-05  1.037957e-05   \n",
       "15071  2.950619e-04  2.689785e-07  1.130019e-07  1.237655e-04  1.530813e-04   \n",
       "18238  2.276023e-06  7.261931e-09  1.323213e-08  1.236932e-06  9.750028e-05   \n",
       "8213   1.684182e-04  8.228342e-07  2.853927e-08  1.049513e-04  1.879991e-03   \n",
       "620    3.635616e-04  1.076119e-07  1.189297e-08  3.461129e-09  1.597586e-05   \n",
       "18399  5.950133e-05  4.967139e-08  2.247101e-07  1.163712e-04  1.068975e-03   \n",
       "15291  1.172222e-07  9.643852e-07  1.020926e-06  4.185727e-07  5.376048e-06   \n",
       "993    7.783605e-07  2.874742e-08  7.552820e-08  5.392986e-08  8.740805e-07   \n",
       "5659   1.411989e-03  1.827057e-08  2.263319e-09  3.262612e-07  1.144319e-04   \n",
       "15804  1.753323e-03  6.695667e-09  9.973665e-10  4.352957e-07  1.340078e-04   \n",
       "4      4.914369e-04  2.590927e-08  4.647548e-08  3.966734e-05  6.949041e-04   \n",
       "8688   5.066686e-05  3.239617e-08  7.286828e-09  1.953560e-04  5.644220e-04   \n",
       "16244  7.041827e-05  1.731204e-06  5.694755e-07  1.082970e-08  1.512749e-06   \n",
       "14635  2.917075e-06  1.005361e-08  1.591131e-07  8.513446e-07  1.916757e-05   \n",
       "5500   4.437590e-05  1.255074e-08  1.608026e-08  5.178069e-06  3.570240e-06   \n",
       "16520  9.715478e-08  3.474597e-12  5.137770e-13  1.054089e-11  1.460893e-06   \n",
       "\n",
       "       ...      ZQNGGY33      ZSHS4VJZ      ZT1IP3T6      ZU6860XU  \\\n",
       "8562   ...  7.095188e-09  2.696536e-07  5.698084e-06  3.874287e-08   \n",
       "9594   ...  1.186578e-07  2.978356e-06  2.222654e-06  1.647494e-06   \n",
       "7025   ...  2.809847e-06  3.824033e-06  4.119010e-07  6.303115e-08   \n",
       "2012   ...  1.073851e-08  4.728307e-06  5.706815e-08  6.395503e-10   \n",
       "9692   ...  6.522609e-06  1.101537e-07  4.936313e-08  2.196971e-07   \n",
       "15071  ...  9.963289e-05  1.215044e-05  1.946164e-04  7.135100e-04   \n",
       "18238  ...  1.013361e-04  1.382394e-07  3.906809e-05  1.596386e-08   \n",
       "8213   ...  1.742810e-05  7.230655e-07  2.311679e-04  1.029956e-06   \n",
       "620    ...  2.254928e-07  3.300600e-06  1.539989e-04  6.316188e-07   \n",
       "18399  ...  5.012733e-04  1.043876e-06  6.470869e-04  3.620759e-07   \n",
       "15291  ...  5.760874e-07  6.894687e-09  1.229060e-07  1.473739e-06   \n",
       "993    ...  1.376041e-06  2.378619e-04  1.139918e-06  7.784023e-07   \n",
       "5659   ...  3.292289e-06  1.017459e-05  4.486286e-07  3.695173e-09   \n",
       "15804  ...  3.279577e-06  5.146978e-06  2.334620e-07  1.474327e-09   \n",
       "4      ...  1.304608e-04  5.380421e-07  2.087675e-04  1.990637e-07   \n",
       "8688   ...  9.478052e-06  1.511690e-05  1.134609e-06  4.078442e-07   \n",
       "16244  ...  4.315825e-08  7.297703e-08  1.210503e-07  2.873316e-10   \n",
       "14635  ...  1.663804e-04  4.207964e-08  3.410388e-04  1.347353e-08   \n",
       "5500   ...  5.410687e-05  3.183095e-07  9.348541e-08  5.418517e-08   \n",
       "16520  ...  1.783351e-13  2.942059e-12  1.059169e-09  5.956728e-14   \n",
       "\n",
       "           ZU6TVFFU      ZU75P59K      ZUI6TDWV      ZWFD8OHC      ZX06ZDZN  \\\n",
       "8562   1.595496e-07  1.010311e-09  3.371859e-08  1.439377e-09  4.872080e-08   \n",
       "9594   3.371715e-06  3.072278e-09  1.336448e-07  5.312367e-09  2.790057e-04   \n",
       "7025   1.007823e-05  2.838526e-09  2.661973e-04  1.807503e-05  1.281278e-04   \n",
       "2012   2.369316e-04  1.449478e-07  1.065736e-06  2.320280e-09  1.875290e-06   \n",
       "9692   3.247159e-05  3.236089e-09  5.265978e-06  1.915174e-07  3.581877e-09   \n",
       "15071  1.328416e-04  7.727913e-08  5.883546e-04  2.205955e-04  1.709917e-04   \n",
       "18238  2.422226e-07  3.191004e-06  1.098435e-08  6.037899e-06  5.767361e-08   \n",
       "8213   1.893149e-07  1.277094e-08  2.825465e-06  5.380128e-05  4.222040e-06   \n",
       "620    5.772490e-06  3.032196e-06  4.374311e-09  5.986251e-09  5.254447e-06   \n",
       "18399  1.840537e-07  1.389077e-09  2.058312e-07  8.195628e-04  3.422509e-07   \n",
       "15291  1.470544e-04  2.111852e-09  9.235870e-06  5.243374e-09  4.289754e-09   \n",
       "993    1.227150e-05  6.533272e-05  4.506002e-07  7.060590e-08  4.375961e-06   \n",
       "5659   1.410119e-05  6.299644e-07  2.257600e-08  6.167449e-09  6.324326e-07   \n",
       "15804  9.122199e-06  4.641185e-07  9.350890e-09  2.217516e-09  2.615995e-07   \n",
       "4      9.806715e-08  7.039285e-10  1.078667e-07  3.371315e-04  1.739712e-07   \n",
       "8688   4.091639e-05  1.652965e-08  1.033150e-03  4.969766e-05  3.294564e-04   \n",
       "16244  3.803409e-06  1.270492e-07  1.812805e-10  2.399371e-11  1.382957e-10   \n",
       "14635  6.088542e-09  1.909283e-10  1.241285e-08  8.412393e-07  1.228447e-08   \n",
       "5500   2.442954e-05  3.115276e-05  7.324467e-07  5.949491e-08  1.205146e-07   \n",
       "16520  1.137713e-12  9.778938e-11  1.190961e-16  1.631349e-15  1.725162e-10   \n",
       "\n",
       "           ZZJVE4HO  \n",
       "8562   5.264684e-08  \n",
       "9594   1.313600e-06  \n",
       "7025   4.924133e-08  \n",
       "2012   6.304308e-08  \n",
       "9692   2.703873e-06  \n",
       "15071  3.826671e-06  \n",
       "18238  2.016064e-06  \n",
       "8213   1.447473e-07  \n",
       "620    1.378214e-06  \n",
       "18399  1.688624e-05  \n",
       "15291  4.009480e-07  \n",
       "993    3.663925e-07  \n",
       "5659   1.199149e-08  \n",
       "15804  4.557814e-09  \n",
       "4      8.369440e-06  \n",
       "8688   5.680109e-07  \n",
       "16244  1.353358e-06  \n",
       "14635  3.188349e-05  \n",
       "5500   5.385205e-08  \n",
       "16520  8.730035e-11  \n",
       "\n",
       "[20 rows x 1315 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb3064",
   "metadata": {},
   "source": [
    "### 6. Show and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa6eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub_best_sub = df.reset_index()[df.reset_index().index.isin(pub_index)]\n",
    "# private_best_sub = df.reset_index()[df.reset_index().index.isin(private_index)]\n",
    "\n",
    "\n",
    "# test_set has been encoded with one-hot encoding and give us the ground truth\n",
    "private_test = test_set_sampled[test_set_sampled.index.isin(private_index)]\n",
    "public_test = test_set_sampled[test_set_sampled.index.isin(pub_index)]\n",
    "private_labels = private_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n",
    "public_labels = public_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n",
    "\n",
    "# TODO: private_best_sub and private_labels shape unmatch, pub_best_sub and public_labels shape unmatch\n",
    "\n",
    "top_10_score_private = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "top_1_score_private = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "top_10_score_public = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "top_1_score_public = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "# top_10_score_total = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), df.reset_index().drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "# top_1_score_total = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), df.reset_index().drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "top_10_score_total = top_k_accuracy_score(test_set_sampled.drop(columns=\"sequence_id\").values.argmax(axis=1), df.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "top_1_score_total = top_k_accuracy_score(test_set_sampled.drop(columns=\"sequence_id\").values.argmax(axis=1), df.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "\n",
    "display(f\"Softmax model top-10 private score: {top_10_score_private}\")\n",
    "\n",
    "display(f\"Softmax model top-1 private score: {top_1_score_private}\")\n",
    "\n",
    "\n",
    "display(f\"Softmax model top-10 public score: {top_10_score_public}\")\n",
    "\n",
    "display(f\"Softmax model top-1 public score: {top_1_score_public}\")\n",
    "\n",
    "display(f\"Softmax model top-10 total score: {top_10_score_total}\")\n",
    "\n",
    "display(f\"Softmax model top-1 total score: {top_1_score_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{RESULTS_PATH}softmax_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d8cd4",
   "metadata": {},
   "source": [
    "#### Visualization ideas\n",
    "1. show the data (which features) + label + predicted label（done\n",
    "2. one-hot results (done\n",
    "3. traning, validation, test\n",
    "4. network structure\n",
    "5. the code structure\n",
    "6. limitation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42685a45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the dataset (input)\n",
    "test_values_df_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258d6fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the true label (the ground truth)\n",
    "test_set_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda92a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the column with the maximum value for each row\n",
    "max_columns = test_set_sampled.drop(columns='sequence_id').idxmax(axis=1)\n",
    "\n",
    "# Create a new DataFrame combining 'sequence_id' and the column names\n",
    "result = pd.DataFrame({\n",
    "    'sequence_id': test_set_sampled['sequence_id'],\n",
    "    'lab_of_origin': max_columns\n",
    "})\n",
    "\n",
    "# Display the result\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136b46f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame with shape 10*1315\n",
    "\n",
    "# Exclude the 'sequence_id' column from sorting\n",
    "sort_columns = [col for col in df.columns if col != 'sequence_id']\n",
    "\n",
    "# Sort columns for each row and keep top ten columns\n",
    "sorted_columns = df.apply(lambda row: sorted(zip(row[sort_columns].index, row[sort_columns]), key=lambda x: x[1], reverse=True)[:10], axis=1)\n",
    "# sorted_columns = sorted_columns.reset_index().drop(columns='index')\n",
    "sorted_columns = pd.DataFrame(sorted_columns)\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, axes = plt.subplots(sorted_columns.shape[0], 1, figsize=(6, sorted_columns.shape[0]*3))\n",
    "\n",
    "# Iterate over each row and create a separate plot\n",
    "for idx,(index , sorted_vals) in enumerate(sorted_columns.iterrows()):\n",
    "    # display(sorted_vals)\n",
    "    \n",
    "    sequence_id = df.loc[index, 'sequence_id']\n",
    "    \n",
    "    sorted_val = sorted_vals[0]\n",
    "    \n",
    "    columns, values = zip(*sorted_val)\n",
    "    \n",
    "    # Get the appropriate subplot from the axes\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot the values\n",
    "    bars = ax.bar(columns, values, width=0.5)\n",
    "    \n",
    "    # Set the title as the sequence_id\n",
    "    ax.set_title(sequence_id)\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    ax.set_xticklabels(columns, rotation=90)\n",
    "    \n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.grid(False)\n",
    "    ax.set_ylim(0,1)\n",
    "    \n",
    "    # Add value annotations on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    \n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff069db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix (less than 20 samples could be a good plot to use)\n",
    "# Replace these lists with your true and predicted labels\n",
    "true_labels = result['lab_of_origin']\n",
    "predicted_labels = [i[0][0][0] for _, i in sorted_columns.iterrows()]\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Set labels for the matrix\n",
    "labels = np.unique(true_labels)\n",
    "tick_labels = [f\"True {label}\" for label in labels]\n",
    "col_labels = [f\"Pred {label}\" for label in labels]\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=col_labels, yticklabels=tick_labels)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2084e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output / inference results\n",
    "df_show = pd.DataFrame(df.iloc[0,:]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step: fake a sequence and see the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a7891",
   "metadata": {},
   "source": [
    "### 2. CNN + (Attention) + Softmax\n",
    "without UNK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042bde24",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/cluster/home/yihliu/MLinPharma/capsule-3003146/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17288c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "softmax_model_paths = list(sorted(glob(\"../data/output/4d1a64be-7826-4992-93b4-4e4beddb0c53/tensorboard_logs_csv_logs/*/checkpoints/*.ckpt\")))\n",
    "lab_index_mapping_paths = list(sorted(glob(\"../data/output/4d1a64be-7826-4992-93b4-4e4beddb0c53/tensorboard_logs_csv_logs/*/lab_index_mapping.pkl\")))\n",
    "from altlabs.model.conv1d_softmax_classifier import Conv1dSoftmaxClassifier, ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(350)\n",
    "\n",
    "def predict_dataset(model: Conv1dAttnSoftmaxClassifier, dataset: FactorizationDataset, tta_steps: int) -> np.ndarray:\n",
    "    batch_sampler = FasterBatchSampler(\n",
    "        dataset, 32, shuffle=False,\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    predictions: List[List[float]] = []\n",
    "    with torch.no_grad():\n",
    "        for indices in batch_sampler:\n",
    "            if tta_steps > 0:\n",
    "                tta_predictions = []\n",
    "                for i in range(tta_steps):\n",
    "                    batch = dataset[indices]\n",
    "                    if isinstance(batch[0], tuple):\n",
    "                        (sequences, extra_inputs, _) = batch[\n",
    "                            0\n",
    "                        ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "                    else:\n",
    "                        (sequences, extra_inputs) = batch\n",
    "                    outputs = torch.nn.functional.softmax(model(\n",
    "                        sequences.to(device), extra_inputs.to(device)\n",
    "                    )).tolist()\n",
    "                    tta_predictions.append(np.array(outputs))\n",
    "                predictions.extend(\n",
    "                    np.mean(np.array(tta_predictions), axis=0).tolist()\n",
    "                )\n",
    "            else:\n",
    "                batch = dataset[indices]\n",
    "                if isinstance(batch[0], tuple):\n",
    "                    (sequences, extra_inputs, _) = batch[\n",
    "                        0\n",
    "                    ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "                else:\n",
    "                    (sequences, extra_inputs) = batch\n",
    "                outputs = torch.nn.functional.softmax(model(\n",
    "                    sequences.to(device), extra_inputs.to(device)\n",
    "                )).tolist()\n",
    "                predictions.extend(outputs)\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "sequence_index_mapping = create_index_mapping(\n",
    "    \"ATGC\", include_unkown=True, include_none=False,\n",
    ")\n",
    "sequence_index_mapping[\"N\"] = 0\n",
    "input_columns = train_values_df.drop(columns=[\"sequence_id\", \"groups\", \"output\"]).columns\n",
    "output_columns = train_labels_df.drop(columns=[\"sequence_id\"]).columns\n",
    "occurrences = np.sum(train_labels_df[output_columns].values, axis=0)\n",
    "minimum_occurrences = 2\n",
    "filtered_out_output_columns = output_columns[\n",
    "    occurrences < minimum_occurrences\n",
    "]\n",
    "output_columns = output_columns.drop(filtered_out_output_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f16730",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/cluster/home/yihliu/MLinPharma/capsule-3003146/data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3926d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10\n",
    "# sample_frac = 0.01\n",
    "test_values_df_sampled = test_values_df.sample(sample_size,random_state=1)\n",
    "fold_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for softmax_model_path in softmax_model_paths:\n",
    "    model = Conv1dSoftmaxClassifier.load_from_checkpoint(softmax_model_path)\n",
    "        \n",
    "    dataset = SoftmaxDataset(\n",
    "        test_values_df_sampled,\n",
    "        sequence_index_mapping,\n",
    "        input_columns,\n",
    "        transform_sequence_fn=transform_sequence_fn,\n",
    "        test=True,\n",
    "        bpe=True,\n",
    "    )\n",
    "    \n",
    "    outputs = predict_dataset(model, dataset, 10)\n",
    "    fold_output.append(outputs)\n",
    "final_outputs = np.mean(fold_output, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65622c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_index_mapping[\"N\"] = 0\n",
    "input_columns = train_values_df.drop(columns=[\"sequence_id\", \"groups\", \"output\"]).columns\n",
    "output_columns = train_labels_df.drop(columns=[\"sequence_id\"]).columns\n",
    "occurrences = np.sum(train_labels_df[output_columns].values, axis=0)\n",
    "minimum_occurrences = 2\n",
    "filtered_out_output_columns = output_columns[\n",
    "    occurrences < minimum_occurrences\n",
    "]\n",
    "filtered_out_output_columns = filtered_out_output_columns.append(pd.Index([\"I7FXTVDP\"]))\n",
    "output_columns = output_columns.drop(filtered_out_output_columns)\n",
    "df = pd.DataFrame(\n",
    "    data=final_outputs, columns=output_columns, index=test_values_df_sampled[\"sequence_id\"]\n",
    ")\n",
    "\n",
    "for column in filtered_out_output_columns:\n",
    "    df[column] = 0.0\n",
    "df = df[format_df.drop(columns=[\"sequence_id\"]).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54713708",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_sampled = test_set.iloc[test_values_df_sampled.index]\n",
    "# generate softmax output for pub and private sub sets\n",
    "df = df.reset_index()\n",
    "df.index = test_values_df_sampled.index\n",
    "pub_best_sub = df[df.index.isin(pub_index)]\n",
    "private_best_sub = df[df.index.isin(private_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cd5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub_best_sub = df.reset_index()[df.reset_index().index.isin(pub_index)]\n",
    "# private_best_sub = df.reset_index()[df.reset_index().index.isin(private_index)]\n",
    "private_test = test_set_sampled[test_set_sampled.index.isin(private_index)]\n",
    "public_test = test_set_sampled[test_set_sampled.index.isin(pub_index)]\n",
    "private_labels = private_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n",
    "public_labels = public_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n",
    "\n",
    "\n",
    "unk_eng_plasmids = test_set_sampled[test_set_sampled[\"I7FXTVDP\"] == 1.0][\"sequence_id\"].tolist()\n",
    "test_set_no_unk = test_set_sampled[~test_set_sampled[\"sequence_id\"].isin(unk_eng_plasmids)]\n",
    "# df = df.reset_index()\n",
    "df_no_unk = df[~df[\"sequence_id\"].isin(unk_eng_plasmids)]\n",
    "\n",
    "pub_best_sub_no_unk = df_no_unk[df_no_unk.index.isin(pub_index)]\n",
    "private_best_sub_no_unk = df_no_unk[df_no_unk.index.isin(private_index)]\n",
    "private_test_no_unk = test_set_no_unk[test_set_no_unk.index.isin(private_index)]\n",
    "public_test_no_unk = test_set_no_unk[test_set_no_unk.index.isin(pub_index)]\n",
    "private_labels_no_unk = private_test_no_unk.drop(columns=\"sequence_id\").values.argmax(axis=1)\n",
    "public_labels_no_unk = public_test_no_unk.drop(columns=\"sequence_id\").values.argmax(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "top_10_score_private_no_unk = top_k_accuracy_score(private_labels_no_unk, private_best_sub_no_unk.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "top_1_score_private_no_unk = top_k_accuracy_score(private_labels_no_unk, private_best_sub_no_unk.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "top_10_score_public_no_unk = top_k_accuracy_score(public_labels_no_unk, pub_best_sub_no_unk.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "top_1_score_public_no_unk = top_k_accuracy_score(public_labels_no_unk, pub_best_sub_no_unk.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "\n",
    "\n",
    "top_10_score_total_no_unk = top_k_accuracy_score(test_set_no_unk.drop(columns=\"sequence_id\").values.argmax(axis=1), df_no_unk.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "top_1_score_total_no_unk = top_k_accuracy_score(test_set_no_unk.drop(columns=\"sequence_id\").values.argmax(axis=1), df_no_unk.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "\n",
    "display(f\"Softmax model top-10 private score (no UNK): {top_10_score_private_no_unk}\")\n",
    "\n",
    "display(f\"Softmax model top-1 private score (no UNK): {top_1_score_private_no_unk}\")\n",
    "\n",
    "\n",
    "display(f\"Softmax model top-10 public score (no UNK): {top_10_score_public_no_unk}\")\n",
    "\n",
    "display(f\"Softmax model top-1 public score (no UNK): {top_1_score_public_no_unk}\")\n",
    "\n",
    "display(f\"Softmax model top-10 total score (no UNK): {top_10_score_total_no_unk}\")\n",
    "\n",
    "display(f\"Softmax model top-1 total score (no UNK): {top_1_score_total_no_unk}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(f\"{RESULTS_PATH}results.csv\"):\n",
    "    result_df = pd.read_csv(f\"{RESULTS_PATH}results.csv\")\n",
    "else:\n",
    "    result_df = pd.DataFrame([], columns=[\"Model\", \"Top 10 Score\", \"Top 1 Score\", \"Top 10 New Data Score\", \"Top 1 New Data Score\", \"Top 10 Total Score\", \"Top 1 Total Score\"])\n",
    "    \n",
    "\n",
    "result_df = result_df.append({\"Model\": \"Softmax model\", \n",
    "                              \"Top 10 Score\": top_10_score_private, \"Top 1 Score\": top_1_score_private, \n",
    "                              \"Top 10 New Data Score\": top_10_score_public, \"Top 1 New Data Score\": top_1_score_public,\n",
    "                             \"Top 10 Total Score\": top_10_score_total, \"Top 1 Total Score\": top_1_score_total}, ignore_index=True)\n",
    "\n",
    "result_df = result_df.append({\"Model\": \"Softmax model (no UNK)\", \n",
    "                              \"Top 10 Score\": top_10_score_private_no_unk, \"Top 1 Score\": top_1_score_private_no_unk, \n",
    "                              \"Top 10 New Data Score\": top_10_score_public_no_unk, \"Top 1 New Data Score\": top_1_score_public_no_unk,\n",
    "                             \"Top 10 Total Score\": top_10_score_total_no_unk, \"Top 1 Total Score\": top_1_score_total_no_unk}, ignore_index=True)\n",
    "\n",
    "result_df.to_csv(f\"{RESULTS_PATH}results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a448dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e66c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (altlabs)",
   "language": "python",
   "name": "altlabs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
