{"cells":[{"cell_type":"code","execution_count":1,"id":"968b0452","metadata":{},"outputs":[],"source":"import os\nimport functools\nfrom typing import *\nfrom glob import glob\nimport pickle\n\nimport torch\nimport numpy as np\nimport pandas as pd\n\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data.dataloader import DataLoader\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n#from sklearn.manifold import TSNE\nfrom MulticoreTSNE import MulticoreTSNE as TSNE\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial import cKDTree\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom yellowbrick.features import Manifold\nfrom yellowbrick.cluster import KElbowVisualizer, InterclusterDistance, SilhouetteVisualizer\nfrom sklearn.preprocessing import normalize\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom sklearn.cluster import AgglomerativeClustering\nfrom altlabs.index_mapping import create_index_mapping\nfrom altlabs.dataset import (\n    noop,\n    random_roll,\n    _convert_to_indices,\n    SoftmaxDataset,\n    limit_sequence_size,\n    get_random_piece,\n    FactorizationDataset,\n)\nfrom altlabs.torch.data import FasterBatchSampler, NoAutoCollationDataLoader\nfrom altlabs.utils import Pipeline\nfrom pytorch_lightning import seed_everything\nfrom sklearn.metrics import top_k_accuracy_score\n%matplotlib inline"},{"cell_type":"code","execution_count":2,"id":"90b6dc3c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:root:Not using Catalysis: No module named 'catalysis'\n"]},{"name":"stdout","output_type":"stream","text":["stripping - WARNING - Not using Catalysis: No module named 'catalysis'\n"]},{"name":"stderr","output_type":"stream","text":["/home/robot/ds-projects/altlabs_codeocean/code/altlabs/dataset.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  self._sequences = np.array([np.array(s) for s in self._sequences])\n","/home/robot/anaconda3/envs/altlabs/lib/python3.7/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","/home/robot/anaconda3/envs/altlabs/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]},{"name":"stdout","output_type":"stream","text":["Softmax model score: 0.8813320412298475\n"]},{"name":"stderr","output_type":"stream","text":["/home/robot/ds-projects/altlabs_codeocean/code/altlabs/dataset.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  self._sequences = np.array([np.array(s) for s in self._sequences])\n","/home/robot/anaconda3/envs/altlabs/lib/python3.7/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","/home/robot/anaconda3/envs/altlabs/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]},{"name":"stdout","output_type":"stream","text":["Softmax model score: 0.8947229319002731\n"]}],"source":"softmax_model_paths = list(sorted(glob(\"output/56836160-1c29-4909-814d-b37d77e86ffc/tensorboard_logs_csv_logs/*/checkpoints/*.ckpt\")))\nlab_index_mapping_paths = list(sorted(glob(\"output/56836160-1c29-4909-814d-b37d77e86ffc/tensorboard_logs_csv_logs/*/lab_index_mapping.pkl\")))\nfrom altlabs.model.conv1d_attn_softmax_classifier import Conv1dAttnSoftmaxClassifier, ModelConfig"},{"cell_type":"code","execution_count":3,"id":"c9c71e97","metadata":{},"outputs":[],"source":"DATA_PATH = \"../data/\"\ndevice = torch.device(\"cuda:0\")\n\ntrain_values_df = pd.read_csv(f\"{DATA_PATH}train_values_grouped.csv\")\ntrain_labels_df = pd.read_csv(f\"{DATA_PATH}train_labels.csv\")\nformat_df = pd.read_csv(f\"{DATA_PATH}format.csv\")\ntest_values_df = pd.read_csv(f\"{DATA_PATH}test_values.csv\")\ntest_set = pd.read_csv(f\"{DATA_PATH}test_labels.csv\")\npub_id = pd.read_csv(f\"{DATA_PATH}pubsubidx.csv\")"},{"cell_type":"code","execution_count":4,"id":"af0818a5","metadata":{},"outputs":[],"source":"pub_index = pub_id[pub_id.public==True].index\nprivate_index = pub_id[pub_id.public==False].index"},{"cell_type":"code","execution_count":7,"id":"6872e847","metadata":{},"outputs":[],"source":"transform_sequence_fn = Pipeline(\n    random_roll,\n    functools.partial(limit_sequence_size, limit=1000))"},{"cell_type":"code","execution_count":8,"id":"902bc99b","metadata":{},"outputs":[],"source":"seed_everything(350)\n\ndef predict_dataset(model: Conv1dAttnSoftmaxClassifier, dataset: FactorizationDataset, tta_steps: int) -> np.ndarray:\n    batch_sampler = FasterBatchSampler(\n        dataset, 32, shuffle=False,\n    )\n\n    model.to(device)\n    predictions: List[List[float]] = []\n    with torch.no_grad():\n        for indices in batch_sampler:\n            if tta_steps > 0:\n                tta_predictions = []\n                for i in range(tta_steps):\n                    batch = dataset[indices]\n                    if isinstance(batch[0], tuple):\n                        (sequences, extra_inputs, _) = batch[\n                            0\n                        ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n                    else:\n                        (sequences, extra_inputs) = batch\n                    outputs = torch.nn.functional.softmax(model(\n                        sequences.to(device), extra_inputs.to(device)\n                    )).tolist()\n                    tta_predictions.append(np.array(outputs))\n                predictions.extend(\n                    np.mean(np.array(tta_predictions), axis=0).tolist()\n                )\n            else:\n                batch = dataset[indices]\n                if isinstance(batch[0], tuple):\n                    (sequences, extra_inputs, _) = batch[\n                        0\n                    ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n                else:\n                    (sequences, extra_inputs) = batch\n                outputs = torch.nn.functional.softmax(model(\n                    sequences.to(device), extra_inputs.to(device)\n                )).tolist()\n                predictions.extend(outputs)\n\n    return np.array(predictions)\n\nsequence_index_mapping = create_index_mapping(\n    \"ATGC\", include_unkown=True, include_none=False,\n)\nsequence_index_mapping[\"N\"] = 0\ninput_columns = train_values_df.drop(columns=[\"sequence_id\", \"groups\", \"output\"]).columns\noutput_columns = train_labels_df.drop(columns=[\"sequence_id\"]).columns\noccurrences = np.sum(train_labels_df[output_columns].values, axis=0)\nminimum_occurrences = 1\nfiltered_out_output_columns = output_columns[\n    occurrences < minimum_occurrences\n]\noutput_columns = output_columns.drop(filtered_out_output_columns)\n\nfold_output = []\nfor softmax_model_path in softmax_model_paths:\n    model = Conv1dAttnSoftmaxClassifier.load_from_checkpoint(softmax_model_path)\n    \n    model.model_config.positional_encoding = True\n    \n    dataset = SoftmaxDataset(\n        test_values_df,\n        sequence_index_mapping,\n        input_columns,\n        transform_sequence_fn=transform_sequence_fn,\n        test=True,\n        bpe=True,\n    )\n    \n    outputs = predict_dataset(model, dataset, 10)\n    fold_output.append(outputs)\nfinal_outputs = np.mean(fold_output, axis=0)\n\n\ndf = pd.DataFrame(\n    data=final_outputs, columns=output_columns, index=test_values_df[\"sequence_id\"]\n)\n\nfor column in filtered_out_output_columns:\n    df[column] = 0.0\ndf = df[format_df.drop(columns=[\"sequence_id\"]).columns]\n\n\npub_best_sub = df.reset_index()[df.reset_index().index.isin(pub_index)]\nprivate_best_sub = df.reset_index()[df.reset_index().index.isin(private_index)]\nprivate_test = test_set[test_set.index.isin(private_index)]\npublic_test = test_set[test_set.index.isin(pub_index)]\nprivate_labels = private_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\npublic_labels = public_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n\nscore = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n\ndisplay(f\"Softmax model score: {score}\")\n\n"},{"cell_type":"code","execution_count":null,"id":"347b4038","metadata":{},"outputs":[],"source":"import os\nRESULTS_PATH = \"../results/\"\n\nif os.path.exists(f\"{RESULTS_PATH}results.csv\"):\n    result_df = pd.read_csv(f\"{RESULTS_PATH}results.csv\")\nelse:\n    result_df = pd.DataFrame([], columns=[\"Model\", \"Top 10 Score\"])\n    \n\nresult_df = result_df.append({\"Model\": \"Softmax model\", \"Top 10 Score\": score}, ignore_index=True)\n\nresult_df.to_csv(f\"{RESULTS_PATH}results.csv\", index=False)"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":5}