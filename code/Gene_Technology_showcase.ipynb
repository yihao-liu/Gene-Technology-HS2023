{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf824519",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning for  Pharmacology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f94de0",
   "metadata": {},
   "source": [
    "## Task: Predict Lab of Origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8cf69b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23aaccf",
   "metadata": {},
   "source": [
    "## Model 1: CNN + softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb16052",
   "metadata": {},
   "source": [
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4674bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "from typing import *\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "#from sklearn.manifold import TSNE\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from yellowbrick.features import Manifold\n",
    "from yellowbrick.cluster import KElbowVisualizer, InterclusterDistance, SilhouetteVisualizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from altlabs.index_mapping import create_index_mapping\n",
    "from altlabs.dataset import (\n",
    "    noop,\n",
    "    random_roll,\n",
    "    _convert_to_indices,\n",
    "    SoftmaxDataset,\n",
    "    limit_sequence_size,\n",
    "    get_random_piece,\n",
    "    FactorizationDataset,\n",
    ")\n",
    "from altlabs.torch.data import FasterBatchSampler, NoAutoCollationDataLoader\n",
    "from altlabs.utils import Pipeline\n",
    "from pytorch_lightning import seed_everything\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd266b",
   "metadata": {},
   "source": [
    "### 2. Load model(s)\n",
    "- CNN + softmax\n",
    "- CNN + Triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_model_paths = list(sorted(glob(\"../data/output/56836160-1c29-4909-814d-b37d77e86ffc/tensorboard_logs_csv_logs/*/checkpoints/*.ckpt\")))\n",
    "lab_index_mapping_paths = list(sorted(glob(\"../data/output/56836160-1c29-4909-814d-b37d77e86ffc/tensorboard_logs_csv_logs/*/lab_index_mapping.pkl\")))\n",
    "# from altlabs.model.conv1d_attn_softmax_classifier import Conv1dAttnSoftmaxClassifier, ModelConfig\n",
    "# for loading the mode, we need to move .au directory to the root path of git which is capsule-3003146\n",
    "from altlabs.model.conv1d_attn_softmax_classifier import Conv1dAttnSoftmaxClassifier, ModelConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837147e",
   "metadata": {},
   "source": [
    "### 3. Set data and results paths and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caabdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "RESULTS_PATH = \"../results/\"\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "train_values_df = pd.read_csv(f\"{DATA_PATH}train_values_grouped.csv\")\n",
    "train_labels_df = pd.read_csv(f\"{DATA_PATH}train_labels.csv\")\n",
    "format_df = pd.read_csv(f\"{DATA_PATH}format.csv\")\n",
    "test_values_df = pd.read_csv(f\"{DATA_PATH}test_values.csv\")\n",
    "test_set = pd.read_csv(f\"{DATA_PATH}test_labels.csv\")\n",
    "pub_id = pd.read_csv(f\"{DATA_PATH}pubsubidx.csv\")\n",
    "\n",
    "pub_index = pub_id[pub_id.public==True].index\n",
    "private_index = pub_id[pub_id.public==False].index\n",
    "\n",
    "# sample the data for prediction\n",
    "sample_size = 20\n",
    "# sample_frac = 0.01\n",
    "test_values_df_sampled = test_values_df.sample(sample_size,random_state=42)\n",
    "test_set_sampled = test_set.iloc[test_values_df_sampled.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b058dfb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create lab_id:lab_num mapping\n",
    "lab_ids = test_set.columns[1:]\n",
    "\n",
    "lab_num_mapping = {lab_id: f'Lab_{i+1:04d}' for i, lab_id in enumerate(lab_ids)}\n",
    "\n",
    "# display(lab_num_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show input\n",
    "test_values_df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cc485",
   "metadata": {},
   "source": [
    "### 4. Data preprocesse\n",
    "delete labs if there are less than 1 sequence belonging to them in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becff384",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_sequence_fn = Pipeline(\n",
    "    random_roll,\n",
    "    functools.partial(limit_sequence_size, limit=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_index_mapping = create_index_mapping(\n",
    "    \"ATGC\", include_unkown=True, include_none=False,\n",
    ")\n",
    "sequence_index_mapping[\"N\"] = 0\n",
    "\n",
    "input_columns = train_values_df.drop(columns=[\"sequence_id\", \"groups\", \"output\"]).columns\n",
    "output_columns = train_labels_df.drop(columns=[\"sequence_id\"]).columns\n",
    "occurrences = np.sum(train_labels_df[output_columns].values, axis=0)\n",
    "minimum_occurrences = 1\n",
    "filtered_out_output_columns = output_columns[\n",
    "    occurrences < minimum_occurrences\n",
    "]\n",
    "output_columns = output_columns.drop(filtered_out_output_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0435232",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fedfaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show filled out labs (you can increase the minimum_occurences)\n",
    "# thinking about achieving it in an interactive way\n",
    "fooc = pd.DataFrame(filtered_out_output_columns)\n",
    "fooc.rename(columns={0:'filtered_out_labs'}, inplace=True)\n",
    "fooc['lab_num'] = fooc['filtered_out_labs'].map(lab_num_mapping)\n",
    "fooc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5385f75",
   "metadata": {},
   "source": [
    "### 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bd2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(350)\n",
    "\n",
    "def predict_dataset(model: Conv1dAttnSoftmaxClassifier, dataset: FactorizationDataset, tta_steps: int) -> np.ndarray:\n",
    "    batch_sampler = FasterBatchSampler(\n",
    "        dataset, 32, shuffle=False,\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    predictions: List[List[float]] = []\n",
    "    with torch.no_grad():\n",
    "        for indices in batch_sampler:\n",
    "            if tta_steps > 0:\n",
    "                tta_predictions = []\n",
    "                for i in range(tta_steps):\n",
    "                    batch = dataset[indices]\n",
    "                    if isinstance(batch[0], tuple):\n",
    "                        (sequences, extra_inputs, _) = batch[\n",
    "                            0\n",
    "                        ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "                    else:\n",
    "                        (sequences, extra_inputs) = batch\n",
    "                    outputs = torch.nn.functional.softmax(model(\n",
    "                        sequences.to(device), extra_inputs.to(device)\n",
    "                    )).tolist()\n",
    "                    tta_predictions.append(np.array(outputs))\n",
    "                predictions.extend(\n",
    "                    np.mean(np.array(tta_predictions), axis=0).tolist()\n",
    "                )\n",
    "            else:\n",
    "                batch = dataset[indices]\n",
    "                if isinstance(batch[0], tuple):\n",
    "                    (sequences, extra_inputs, _) = batch[\n",
    "                        0\n",
    "                    ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "                else:\n",
    "                    (sequences, extra_inputs) = batch\n",
    "                outputs = torch.nn.functional.softmax(model(\n",
    "                    sequences.to(device), extra_inputs.to(device)\n",
    "                )).tolist()\n",
    "                predictions.extend(outputs)\n",
    "\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7fa256",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jovyan/Gene-Technology-HS2023/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d75707",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fold_output = []\n",
    "for softmax_model_path in softmax_model_paths:\n",
    "    model = Conv1dAttnSoftmaxClassifier.load_from_checkpoint(softmax_model_path)\n",
    "    model.model_config.positional_encoding = True\n",
    "    \n",
    "    dataset = SoftmaxDataset(\n",
    "        test_values_df_sampled, # only for the showcase, for the exact resulst replace it with test_values_df\n",
    "        sequence_index_mapping,\n",
    "        input_columns,\n",
    "        transform_sequence_fn=transform_sequence_fn,\n",
    "        test=True,\n",
    "        bpe=True,\n",
    "    )\n",
    "    outputs = predict_dataset(model, dataset, 10)\n",
    "    fold_output.append(outputs)\n",
    "final_outputs = np.mean(fold_output, axis=0)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=final_outputs, columns=output_columns, index=test_values_df_sampled[\"sequence_id\"]\n",
    ")\n",
    "\n",
    "\n",
    "for column in filtered_out_output_columns:\n",
    "    df[column] = 0.0\n",
    "df = df[format_df.drop(columns=[\"sequence_id\"]).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad8560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate softmax output for pub and private sub sets\n",
    "df = df.reset_index()\n",
    "df.index = test_values_df_sampled.index\n",
    "pub_best_sub = df[df.index.isin(pub_index)]\n",
    "private_best_sub = df[df.index.isin(private_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19366201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the direct output after softmax\n",
    "new_column_names = {col: lab_num_mapping[col] for col in df.columns if col in lab_num_mapping}\n",
    "df.rename(columns=new_column_names, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136b46f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exclude the 'sequence_id' column from sorting\n",
    "sort_columns = [col for col in df.columns if col != 'sequence_id']\n",
    "\n",
    "# Sort columns for each row and keep top ten columns\n",
    "sorted_columns = df.apply(lambda row: sorted(zip(row[sort_columns].index, row[sort_columns]), key=lambda x: x[1], reverse=True)[:10], axis=1)\n",
    "# sorted_columns = sorted_columns.reset_index().drop(columns='index')\n",
    "sorted_columns = pd.DataFrame(sorted_columns)\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, axes = plt.subplots(sorted_columns.shape[0], 1, figsize=(6, sorted_columns.shape[0]*3))\n",
    "\n",
    "# Iterate over each row and create a separate plot\n",
    "for idx,(index , sorted_vals) in enumerate(sorted_columns.iterrows()):\n",
    "    # display(sorted_vals)\n",
    "    \n",
    "    sequence_id = df.loc[index, 'sequence_id']\n",
    "    \n",
    "    sorted_val = sorted_vals[0]\n",
    "    \n",
    "    columns, values = zip(*sorted_val)\n",
    "    \n",
    "    # Get the appropriate subplot from the axes\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot the values\n",
    "    bars = ax.bar(columns, values, width=0.5)\n",
    "    \n",
    "    # Set the title as the sequence_id\n",
    "    ax.set_title('Sequence id:'+sequence_id)\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    ax.set_xticklabels(columns, rotation=45)\n",
    "    \n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_xlabel('Lab of origin')\n",
    "\n",
    "    ax.grid(False)\n",
    "    ax.set_ylim(0,1)\n",
    "    \n",
    "    # Add value annotations on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    \n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the true label (the ground truth)\n",
    "test_set_sampled_copy = test_set_sampled.copy()\n",
    "test_set_sampled_copy.rename(columns=new_column_names, inplace=True)\n",
    "test_set_sampled_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda92a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the column with the maximum value for each row\n",
    "max_columns = test_set_sampled_copy.drop(columns='sequence_id').idxmax(axis=1)\n",
    "\n",
    "# Create a new DataFrame combining 'sequence_id' and the column names\n",
    "result = pd.DataFrame({\n",
    "    'sequence_id': test_set_sampled_copy['sequence_id'],\n",
    "    'lab_of_origin': max_columns\n",
    "})\n",
    "\n",
    "# Display the result\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db76cd28",
   "metadata": {},
   "source": [
    "### 6. Show and save results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e251de",
   "metadata": {},
   "source": [
    "before showing the performance of the model, let's guess the accuracy if the model did not learn anything but random guess (be aware that the training data is unbalanced!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use argsort to get the indices that would sort the array in ascending order\n",
    "sorted_indices = np.argsort(occurrences)\n",
    "\n",
    "# Get the indices of the top 10 maximum values (last 10 indices after sorting in ascending order)\n",
    "top_10_indices = sorted_indices[-10:]\n",
    "\n",
    "# Rearrange the data in descending order\n",
    "top_10_indices = top_10_indices[::-1]\n",
    "\n",
    "output_columns_num = output_columns.map(lab_num_mapping)\n",
    "# Create the dot plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(output_columns_num[top_10_indices], occurrences[top_10_indices], 'o', markersize=10)\n",
    "plt.xlabel('Lab of origin')\n",
    "plt.ylabel('Occurrences times')\n",
    "plt.title('Lab occurrences')\n",
    "\n",
    "# Rotate the x-labels\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add the values to each dot\n",
    "for i in top_10_indices:\n",
    "    plt.text(output_columns_num[i], occurrences[i], str(occurrences[i])[:-2], ha='center', va='bottom')\n",
    "\n",
    "\n",
    "plt.grid(axis='y')  # Add gridlines on the y-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training = train_labels_df.shape[0]\n",
    "\n",
    "# Create the dot plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(output_columns_num[top_10_indices], occurrences[top_10_indices]/num_training, 'o', markersize=10)\n",
    "plt.xlabel('Lab of origin')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Majority guess accuracy')\n",
    "\n",
    "# Rotate the x-labels\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add the values to each dot\n",
    "for i in top_10_indices:\n",
    "    plt.text(output_columns_num[i], occurrences[i]/num_training, format(occurrences[i]/num_training,'.4f'), ha='center', va='bottom')\n",
    "\n",
    "\n",
    "plt.grid(axis='y')  # Add gridlines on the y-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84949fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_occurrences = np.max(occurrences)\n",
    "min_occurrences = np.min(occurrences)\n",
    "num_training = train_labels_df.shape[0]\n",
    "max_guess_accuracy = format(max_occurrences/num_training,'.6f')\n",
    "min_guess_accuracy = format(min_occurrences/num_training,'.6f')\n",
    "display(f'The majority guess accuracy is between {min_guess_accuracy} and {max_guess_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f58054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Maybe we do not need this top-10 accuracy\n",
    "# # Use argsort to get the indices that would sort the array in ascending order\n",
    "# sorted_indices = np.argsort(occurrences)\n",
    "\n",
    "# # Get the indices of the top 10 maximum values (last 10 indices after sorting in ascending order)\n",
    "# top_10_indices = sorted_indices[-10:]\n",
    "\n",
    "# # Use these indices to get the top 10 maximum values\n",
    "# top_10_max_values = occurrences[top_10_indices]\n",
    "\n",
    "# random_guess_accuracy_top10 = format(np.sum(top_10_max_values)/num_training,'.4f')\n",
    "# display(f\"The highest top-10 accuracy (if we always choose the lab with most sequences) can reach {random_guess_accuracy_top10}\")\n",
    "# # display(top_10_max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa6eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub_best_sub = df.reset_index()[df.reset_index().index.isin(pub_index)]\n",
    "# private_best_sub = df.reset_index()[df.reset_index().index.isin(private_index)]\n",
    "\n",
    "\n",
    "# test_set has been encoded with one-hot encoding and give us the ground truth\n",
    "private_test = test_set_sampled[test_set_sampled.index.isin(private_index)]\n",
    "public_test = test_set_sampled[test_set_sampled.index.isin(pub_index)]\n",
    "private_labels = private_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n",
    "public_labels = public_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n",
    "\n",
    "# TODO: private_best_sub and private_labels shape unmatch, pub_best_sub and public_labels shape unmatch\n",
    "\n",
    "# top_10_score_private = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "# top_1_score_private = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "# top_10_score_public = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "# top_1_score_public = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "# top_10_score_total = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), df.reset_index().drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "# top_1_score_total = top_k_accuracy_score(test_set.drop(columns=\"sequence_id\").values.argmax(axis=1), df.reset_index().drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "top_10_score_total = top_k_accuracy_score(test_set_sampled.drop(columns=\"sequence_id\").values.argmax(axis=1), df.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "top_1_score_total = top_k_accuracy_score(test_set_sampled.drop(columns=\"sequence_id\").values.argmax(axis=1), df.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "\n",
    "# display(f\"Softmax model top-10 private score: {top_10_score_private}\")\n",
    "\n",
    "# display(f\"Softmax model top-1 private score: {top_1_score_private}\")\n",
    "\n",
    "# display(f\"Softmax model top-10 public score: {top_10_score_public}\")\n",
    "\n",
    "# display(f\"Softmax model top-1 public score: {top_1_score_public}\")\n",
    "\n",
    "display(f\"Softmax model top-10 total score: {top_10_score_total}\")\n",
    "\n",
    "display(f\"Softmax model top-1 total score: {top_1_score_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{RESULTS_PATH}softmax_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff069db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# confusion matrix (less than 20 samples could be a good plot to use)\n",
    "# Replace these lists with your true and predicted labels\n",
    "true_labels = result['lab_of_origin']\n",
    "predicted_labels = [i[0][0][0] for _, i in sorted_columns.iterrows()]\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Set labels for the matrix\n",
    "labels = np.unique(np.union1d(predicted_labels, true_labels))\n",
    "tick_labels = [label for label in labels]\n",
    "col_labels = [label for label in labels]\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=col_labels, yticklabels=tick_labels)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6309fcbb",
   "metadata": {},
   "source": [
    "#### Calibration (not working right now, because we sampled too little data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a991d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the ground truth labels (you may have this from your data)\n",
    "# # For example, if your ground truth labels are in a separate DataFrame column:\n",
    "# # y_true = df['Ground_Truth_Label'].values\n",
    "# y_true = result['lab_of_origin'].values  # Replace with your actual ground truth labels\n",
    "\n",
    "# # Extract the predicted probabilities (excluding the Sequence ID column)\n",
    "# # Here, we assume that the class columns start from the second column (index 1)\n",
    "# y_probs = df.iloc[:, 1:].values\n",
    "\n",
    "# # Number of classes\n",
    "# num_classes = y_probs.shape[1]\n",
    "\n",
    "# # Calculate the calibration curve for each class\n",
    "# prob_true_by_class = []\n",
    "# prob_pred_by_class = []\n",
    "\n",
    "# for class_idx in range(num_classes):\n",
    "#     class_probs = y_probs[:, class_idx]\n",
    "#     prob_true, prob_pred = calibration_curve(y_true=y_true == class_idx, y_prob=class_probs, n_bins=10)\n",
    "#     prob_true_by_class.append(prob_true)\n",
    "#     prob_pred_by_class.append(prob_pred)\n",
    "\n",
    "# # Plot the calibration curves for each class\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# for class_idx in range(num_classes):\n",
    "#     plt.plot(prob_pred_by_class[class_idx], prob_true_by_class[class_idx],\n",
    "#              marker='o', linestyle='-', label=f'Class {class_idx+1}')\n",
    "\n",
    "# # Add the diagonal line (perfect calibration)\n",
    "# plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Perfect Calibration')\n",
    "\n",
    "# plt.xlabel('Mean Predicted Probability')\n",
    "# plt.ylabel('Fraction of Positives')\n",
    "# plt.title('Calibration Plot (Per Class)')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a7891",
   "metadata": {},
   "source": [
    "## Model 2: CNN + triplet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042bde24",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jovyan/Gene-Technology-HS2023/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17288c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "triplet_model_paths = list(sorted(glob(\"../data/output/daaefeed-3f3f-43a0-b7c2-2abf04e31e72/tensorboard_logs_csv_logs/*/checkpoints/*.ckpt\")))\n",
    "lab_index_mapping_paths = list(sorted(glob(\"../data/output/daaefeed-3f3f-43a0-b7c2-2abf04e31e72/tensorboard_logs_csv_logs/*/lab_index_mapping.pkl\")))\n",
    "from altlabs.model.conv1d_triplet_classifier import Conv1dTripletClassifier, ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jovyan/Gene-Technology-HS2023/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seed_everything(350)\n",
    "\n",
    "def predict_dataset(model: Conv1dTripletClassifier, dataset: FactorizationDataset, tta_steps: int) -> np.ndarray:\n",
    "    batch_sampler = FasterBatchSampler(\n",
    "        dataset, 32, shuffle=False,\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    predictions: List[List[float]] = []\n",
    "    with torch.no_grad():\n",
    "        for indices in batch_sampler:\n",
    "            if tta_steps > 0:\n",
    "                tta_predictions = []\n",
    "                for i in range(tta_steps):\n",
    "                    batch = dataset[indices]\n",
    "                    if isinstance(batch[0], tuple):\n",
    "                        (sequences, extra_inputs, _) = batch[\n",
    "                            0\n",
    "                        ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "                    else:\n",
    "                        (sequences, extra_inputs) = batch\n",
    "                    outputs = model.predict_lab_scores(\n",
    "                        sequences.to(device), extra_inputs.to(device)\n",
    "                    ).tolist()\n",
    "                    tta_predictions.append(np.array(outputs))\n",
    "                predictions.extend(\n",
    "                    np.mean(np.array(tta_predictions), axis=0).tolist()\n",
    "                )\n",
    "            else:\n",
    "                batch = dataset[indices]\n",
    "                if isinstance(batch[0], tuple):\n",
    "                    (sequences, extra_inputs, _) = batch[\n",
    "                        0\n",
    "                    ]  # type: (torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "                else:\n",
    "                    (sequences, extra_inputs) = batch\n",
    "                outputs = model.predict_lab_scores(\n",
    "                    sequences.to(device), extra_inputs.to(device)\n",
    "                ).tolist()\n",
    "                predictions.extend(outputs)\n",
    "\n",
    "    return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ddec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_index_mapping = create_index_mapping(\n",
    "\"ATGC\", include_unkown=True, include_none=False,\n",
    ")\n",
    "sequence_index_mapping[\"N\"] = 0\n",
    "input_columns = train_values_df.drop(columns=[\"sequence_id\", \"groups\", \"output\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ac132",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_output = []\n",
    "for triplet_model_path, lab_index_mapping_path in zip(triplet_model_paths, lab_index_mapping_paths):\n",
    "    model = Conv1dTripletClassifier.load_from_checkpoint(triplet_model_path)\n",
    "    with open(lab_index_mapping_path, \"rb\") as f:\n",
    "        lab_index_mapping = pickle.load(f)\n",
    "        \n",
    "    dataset = FactorizationDataset(\n",
    "        test_values_df_sampled,\n",
    "        sequence_index_mapping,\n",
    "        lab_index_mapping,\n",
    "        input_columns,\n",
    "        lab_column=\"output\",\n",
    "        negative_proportion=0.0,\n",
    "        transform_sequence_fn=random_roll,\n",
    "        test=True,\n",
    "        bpe=True,\n",
    "    )\n",
    "\n",
    "    outputs = predict_dataset(model, dataset, 10)\n",
    "    fold_output.append(outputs)\n",
    "    break # we only use one triplet model for the showcase, because of the time and the resource limitation\n",
    "    \n",
    "final_outputs = np.mean(fold_output, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262efeb4",
   "metadata": {},
   "source": [
    "#### A problem found in the code: lab_index_mapping misses two labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac68529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why the lab_index_mapping is not of the shape we want, and miss two labs\n",
    "[col for col in test_set_sampled.columns if col not in lab_index_mapping.keys()]\n",
    "# the problem is caused by lab_index_mapping (it only have 1312 mapping relationship but we have 1314 in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412fc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(np.sum(test_set['0L3Y6ZB2']))\n",
    "display(np.sum(test_set['ON9AXMKF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f963ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_df_sampled = format_df.iloc[test_set_sampled.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the final_outputs[:,0] to fill the inference of ['0L3Y6ZB2', 'ON9AXMKF']\n",
    "for lab in format_df_sampled.columns[1:]:\n",
    "    lab_index = lab_index_mapping[lab]\n",
    "    if lab == 'ZT1IP3T6':\n",
    "        display(lab_index)\n",
    "    format_df_sampled[lab] = final_outputs[:, lab_index]\n",
    "\n",
    "format_df_sampled = format_df_sampled.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_best_sub = format_df_sampled[format_df_sampled.index.isin(pub_index)]\n",
    "private_best_sub = format_df_sampled[format_df_sampled.index.isin(private_index)]\n",
    "private_test = test_set_sampled[test_set_sampled.index.isin(private_index)]\n",
    "public_test = test_set_sampled[test_set_sampled.index.isin(pub_index)]\n",
    "private_labels = private_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n",
    "public_labels = public_test.drop(columns=\"sequence_id\").values.argmax(axis=1)\n",
    "\n",
    "# top_10_score_private = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "# top_1_score_private = top_k_accuracy_score(private_labels, private_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "# top_10_score_public = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "# top_1_score_public = top_k_accuracy_score(public_labels, pub_best_sub.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "top_10_score_total = top_k_accuracy_score(test_set_sampled.drop(columns=\"sequence_id\").values.argmax(axis=1), format_df_sampled.drop(columns=\"sequence_id\").values, k=10, labels=range(0,1314))\n",
    "\n",
    "top_1_score_total = top_k_accuracy_score(test_set_sampled.drop(columns=\"sequence_id\").values.argmax(axis=1), format_df_sampled.drop(columns=\"sequence_id\").values, k=1, labels=range(0,1314))\n",
    "\n",
    "\n",
    "\n",
    "# display(f\"Triplet model top-10 private score: {top_10_score_private}\")\n",
    "\n",
    "# display(f\"Triplet model top-1 private score: {top_1_score_private}\")\n",
    "\n",
    "\n",
    "# display(f\"Triplet model top-10 public score: {top_10_score_public}\")\n",
    "\n",
    "# display(f\"Triplet model top-1 public score: {top_1_score_public}\")\n",
    "\n",
    "display(f\"Triplet model top-10 total score: {top_10_score_total}\")\n",
    "\n",
    "display(f\"Triplet model top-1 total score: {top_1_score_total}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f16730",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_df_sampled.to_csv(f\"{RESULTS_PATH}triplet_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a81ea39",
   "metadata": {},
   "source": [
    "### 7. Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef243c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the column with the maximum value for each row\n",
    "format_df_sampled_copy = format_df_sampled.copy()\n",
    "format_df_sampled_copy.rename(columns=new_column_names, inplace=True)\n",
    "# format_df_sampled_copy\n",
    "max_columns = format_df_sampled_copy.drop(columns='sequence_id').idxmax(axis=1)\n",
    "\n",
    "# Create a new DataFrame combining 'sequence_id' and the column names\n",
    "result = pd.DataFrame({\n",
    "    'sequence_id': test_set_sampled_copy['sequence_id'],\n",
    "    'lab_of_origin': max_columns\n",
    "})\n",
    "\n",
    "# Display the result\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 'sequence_id' column from sorting\n",
    "sort_columns = [col for col in format_df_sampled_copy.columns if col != 'sequence_id']\n",
    "\n",
    "# Sort columns for each row and keep top ten columns\n",
    "sorted_columns = df.apply(lambda row: sorted(zip(row[sort_columns].index, row[sort_columns]), key=lambda x: x[1], reverse=True)[:10], axis=1)\n",
    "# sorted_columns = sorted_columns.reset_index().drop(columns='index')\n",
    "sorted_columns = pd.DataFrame(sorted_columns)\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, axes = plt.subplots(sorted_columns.shape[0], 1, figsize=(6, sorted_columns.shape[0]*3))\n",
    "\n",
    "# Iterate over each row and create a separate plot\n",
    "for idx,(index , sorted_vals) in enumerate(sorted_columns.iterrows()):\n",
    "    # display(sorted_vals)\n",
    "    \n",
    "    sequence_id = format_df_sampled.loc[index, 'sequence_id']\n",
    "    \n",
    "    sorted_val = sorted_vals[0]\n",
    "    \n",
    "    columns, values = zip(*sorted_val)\n",
    "    \n",
    "    # Get the appropriate subplot from the axes\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot the values\n",
    "    bars = ax.bar(columns, values, width=0.5)\n",
    "    \n",
    "    # Set the title as the sequence_id\n",
    "    ax.set_title('Sequence id:'+sequence_id)\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    ax.set_xticklabels(columns, rotation=45)\n",
    "    \n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_xlabel('Lab of origin')\n",
    "    ax.grid(False)\n",
    "    ax.set_ylim(0,1)\n",
    "    \n",
    "    # Add value annotations on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    \n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix (less than 20 samples could be a good plot to use)\n",
    "# Replace these lists with your true and predicted labels\n",
    "true_labels = result['lab_of_origin'].values\n",
    "predicted_labels = [i[0][0][0] for _, i in sorted_columns.iterrows()]\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Set labels for the matrix\n",
    "labels = np.unique(np.union1d(predicted_labels, true_labels))\n",
    "tick_labels = [label for label in labels]\n",
    "col_labels = [label for label in labels]\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=col_labels, yticklabels=tick_labels)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
